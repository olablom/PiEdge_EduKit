{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PiEdge EduKit ‚Äî Guided Demo (Smoke Test)\n",
    "\n",
    "## Why this notebook exists\n",
    "A **guided demo** that runs the entire pipeline once so you can validate the environment and see the end-to-end flow before doing anything more advanced. It mirrors the mini-project \"cutlery sorter\" (Edge ML on Raspberry Pi): train a tiny classifier locally, export to ONNX, benchmark latency, attempt INT8 quantization, evaluate, and verify.\n",
    "\n",
    "## Purpose\n",
    "- Give a **practical overview** of a small Edge-ML workflow from code to measurable results.\n",
    "- Show why **ONNX** matters (same model runs on PC and Pi).\n",
    "- Teach how to read **latency metrics** (p50/p95) and why **warm-up** matters.\n",
    "- Demonstrate that **INT8 quantization may fail** on some machines and that **FP32 fallback** is acceptable in this lesson.\n",
    "\n",
    "## What you will learn\n",
    "- The pipeline: **Train ‚Üí Export (ONNX) ‚Üí Benchmark ‚Üí Quantize ‚Üí Evaluate ‚Üí Verify**.\n",
    "- How to interpret **p50/p95** and perform proper **warm-up** before timing.\n",
    "- Differences between **FP32** and **INT8** (size/latency/compatibility).\n",
    "- Where artifacts are saved and how they're used: `models/`, `reports/`, `progress/receipt.json`.\n",
    "\n",
    "## What you will produce\n",
    "- `models/model.onnx` ‚Äî exported model.\n",
    "- `reports/training_curves.png` ‚Äî training curves (visible even with 1 epoch).\n",
    "- `reports/latency_plot.png` ‚Äî latency measurement.\n",
    "- `reports/quantization_comparison.png` ‚Äî FP32 vs INT8 comparison (FP32-only if INT8 fails).\n",
    "- `reports/confusion_matrix.png` ‚Äî quick quality snapshot.\n",
    "- `progress/receipt.json` ‚Äî **receipt** with PASS/FAIL and key metrics.\n",
    "\n",
    "## Run modes\n",
    "- **Smoke Test (default, fast):** 1 epoch, few measurements ‚Üí ~2‚Äì3 min. Good for sanity check.\n",
    "- **Pretty Demo (optional):** 5 epochs, more measurements ‚Üí clearer curves & more stable stats (a few minutes extra). Provided via scripts and documented in `README.md` and `index.html`.\n",
    "\n",
    "## Prerequisites\n",
    "- **Python 3.12** inside the repo's local **`.venv`** (see README for activation).\n",
    "- Run from the **repo root** (paths are relative).\n",
    "- Everything runs on your PC. The Raspberry Pi comes later for the GPIO part.\n",
    "\n",
    "## Time budget\n",
    "- Smoke Test: ~2‚Äì3 minutes of active time.\n",
    "- Pretty Demo: ~5‚Äì7 minutes.\n",
    "\n",
    "## Success criteria\n",
    "- Notebook completes without errors.\n",
    "- Artifacts exist in `models/` and `reports/`.\n",
    "- `progress/receipt.json` shows **PASS**.\n",
    "\n",
    "> **Note:** On some Windows setups, ONNX Runtime **INT8** quantization can fail. That is **expected** here; the lesson automatically falls back to **FP32**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before you run\n",
    "\n",
    "**Why this notebook exists**\n",
    "This is a *guided demo* that kicks off the full pipeline so you can verify the environment and see the end-to-end flow once.\n",
    "\n",
    "**Learning goals (quick)**\n",
    "- See the whole path once: **train ‚Üí export (ONNX) ‚Üí benchmark ‚Üí quantize ‚Üí evaluate ‚Üí verify**.\n",
    "- Know what **ONNX** is (portable inference format) and why we export to it.\n",
    "- Understand **latency metrics** (p50/p95) and why **warm-up** matters.\n",
    "- Recognize that **INT8 may fail** on some machines and that **FP32 fallback is acceptable** in this lesson.\n",
    "\n",
    "**Before you run**\n",
    "- Use **Python 3.12** inside the repo‚Äôs **`.venv`** (see README quickstart).\n",
    "- Keep the **repo root** as working directory; paths are relative.\n",
    "- Expect **quiet output** with live timers; warnings are suppressed unless relevant.\n",
    "\n",
    "**Success criteria**\n",
    "- The notebook completes without errors and generates artifacts in `models/`, `reports/`, and a **PASS** receipt in `progress/receipt.json`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportMissingImports=false, reportUndefinedVariable=false, reportAttributeAccessIssue=false\n",
    "import sys, os\n",
    "sys.path.insert(0, os.getcwd())\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), \"src\"))\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Working directory:\", os.getcwd())\n",
    "print(\"sys.path configured for imports\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéõÔ∏è Run Mode Selection\n",
    "\n",
    "Choose your execution mode:\n",
    "\n",
    "**Smoke Test (default)**: Fast pipeline verification (1 epoch, 3 benchmark runs, 32 eval samples)\n",
    "- ‚úÖ Quick completion (~2-3 minutes)\n",
    "- ‚úÖ Shows 1-point training curves (with markers)\n",
    "- ‚úÖ Perfect for environment verification\n",
    "- ‚úÖ Gives PASS in verify.py\n",
    "\n",
    "**Pretty Demo**: Nice graphs for classroom (5 epochs, 200 benchmark runs, 200 eval samples)\n",
    "- üìà Clear training curves (5 points)\n",
    "- üìä Stable confusion matrix\n",
    "- ‚è±Ô∏è Takes ~5-7 minutes\n",
    "- ‚úÖ Also gives PASS in verify.py\n",
    "\n",
    "---\n",
    "\n",
    "## TODO: Run the complete pipeline\n",
    "\n",
    "This notebook demonstrates the full ML pipeline. Follow these steps:\n",
    "\n",
    "1. **Train** a model using the training script\n",
    "2. **Export** the model to ONNX format\n",
    "3. **Benchmark** inference latency\n",
    "4. **Quantize** to INT8 (may fail on some systems)\n",
    "5. **Evaluate** model performance\n",
    "6. **Verify** all artifacts are generated correctly\n",
    "\n",
    "<details><summary>Hint</summary>\n",
    "Each step generates artifacts in specific directories. Check `models/`, `reports/`, and `progress/` folders.\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution</summary>\n",
    "Run each cell in sequence. The pipeline will automatically generate all required artifacts and create a verification receipt.\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "# 00 - Run Everything (Demo)\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "* See the complete ML pipeline from training to verification\n",
    "* Understand the purpose of each step in the workflow\n",
    "* Verify that the environment is properly configured\n",
    "\n",
    "## Concepts\n",
    "\n",
    "**Pipeline flow**: train ‚Üí export ‚Üí benchmark ‚Üí quantize ‚Üí evaluate ‚Üí verify\n",
    "\n",
    "**ONNX export**: converts PyTorch models to portable format for edge deployment\n",
    "\n",
    "**Latency benchmarking**: measures inference performance with warm-up and percentiles\n",
    "\n",
    "**Quantization**: reduces model precision (FP32 ‚Üí INT8) for faster inference\n",
    "\n",
    "**Verification**: automated checks ensure all components work correctly\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "* Running without proper Python 3.12 environment setup\n",
    "* Missing dependencies or incorrect package installation\n",
    "* File path issues when not running from repo root\n",
    "* Expecting perfect accuracy on synthetic data\n",
    "\n",
    "## Success Criteria\n",
    "\n",
    "* ‚úÖ All pipeline steps complete without errors\n",
    "* ‚úÖ Artifacts generated in correct directories\n",
    "* ‚úÖ Receipt shows PASS status\n",
    "* ‚úÖ Can explain purpose of each pipeline step\n",
    "\n",
    "## Reflection\n",
    "\n",
    "After completing this demo, reflect on:\n",
    "- Which step took the longest and why?\n",
    "- What surprised you about the pipeline flow?\n",
    "- How does this compare to other ML workflows you've seen?\n",
    "\n",
    "---\n",
    "\n",
    "# üöÄ PiEdge EduKit - Quick Run & Sanity Check\n",
    "\n",
    "## What you'll learn today\n",
    "\n",
    "* Train a tiny image classifier in PyTorch\n",
    "* Export the model to **ONNX** (a portable format for deployment)\n",
    "* Measure inference latency and interpret P50/P95\n",
    "* (Try to) quantize to INT8 and understand why it may fail\n",
    "* Evaluate the model and record a reproducible \"receipt\"\n",
    "\n",
    "## Why this matters\n",
    "\n",
    "Most real projects train in Python but deploy elsewhere (C++, mobile, web, embedded). ONNX lets us move models **out of Python** without rewriting the model by hand.\n",
    "\n",
    "## How to use this notebook\n",
    "\n",
    "This is a **smoke test**: it runs the whole pipeline end-to-end so your environment is correct. For learning and coding tasks, continue with **`01_training_and_export.ipynb`** ‚Üí **`04_evaluate_and_verify.ipynb`**.\n",
    "\n",
    "---\n",
    "\n",
    "## ONNX 101\n",
    "\n",
    "**What is ONNX?**\n",
    "ONNX (Open Neural Network Exchange) is an **open standard** for representing ML models as a graph of operators (Conv, Relu, MatMul‚Ä¶). Many frameworks can **export** to ONNX (PyTorch, TensorFlow) and many runtimes can **execute** ONNX (ONNX Runtime, TensorRT, CoreML Tools).\n",
    "\n",
    "**Why ONNX?**\n",
    "\n",
    "* **Portability**: train in Python, deploy in C++/C#/Java/JS, mobile or edge.\n",
    "* **Performance**: runtimes fuse ops and call optimized backends (MKL, cuDNN).\n",
    "* **Interoperability**: one model file can run across platforms with different \"Execution Providers\" (CPU, CUDA, DirectML, NNAPI‚Ä¶).\n",
    "\n",
    "**Key terms**\n",
    "\n",
    "* **Opset**: version of the operator set supported by runtimes. We export with a specific opset (e.g., 17).\n",
    "* **Static vs dynamic shapes**: fixed sizes are simpler/faster; dynamic adds flexibility.\n",
    "* **Execution Provider (EP)**: the backend used by ONNX Runtime (e.g., `CPUExecutionProvider`).\n",
    "* **Pre/Post-processing**: steps around the model (resize, normalize, label mapping). These **aren't** part of the ONNX graph; the app must do the same steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Mode Configuration\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Create radio buttons for run mode selection\n",
    "mode_radio = widgets.RadioButtons(\n",
    "    options=[\n",
    "        ('Smoke Test (1 epoch, fast)', 'smoke'),\n",
    "        ('Pretty Demo (5 epochs, nice graphs)', 'pretty')\n",
    "    ],\n",
    "    value='smoke',\n",
    "    description='Run Mode:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Display the radio buttons\n",
    "display(mode_radio)\n",
    "\n",
    "# Set parameters based on selection\n",
    "if mode_radio.value == 'smoke':\n",
    "    EPOCHS = 1\n",
    "    BATCH_SIZE = 256\n",
    "    WARMUP_RUNS = 1\n",
    "    BENCHMARK_RUNS = 3\n",
    "    EVAL_LIMIT = 32\n",
    "    print(\"‚úÖ Smoke Test mode selected\")\n",
    "    print(\"   - Training: 1 epoch, batch-size 256\")\n",
    "    print(\"   - Benchmark: 1 warmup, 3 runs\")\n",
    "    print(\"   - Evaluation: 32 samples\")\n",
    "else:\n",
    "    EPOCHS = 5\n",
    "    BATCH_SIZE = 16\n",
    "    WARMUP_RUNS = 50\n",
    "    BENCHMARK_RUNS = 200\n",
    "    EVAL_LIMIT = 200\n",
    "    print(\"üìà Pretty Demo mode selected\")\n",
    "    print(\"   - Training: 5 epochs, batch-size 16\")\n",
    "    print(\"   - Benchmark: 50 warmup, 200 runs\")\n",
    "    print(\"   - Evaluation: 200 samples\")\n",
    "\n",
    "print(f\"\\nParameters set: epochs={EPOCHS}, batch_size={BATCH_SIZE}, warmup={WARMUP_RUNS}, runs={BENCHMARK_RUNS}, limit={EVAL_LIMIT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup & Verifiering\n",
    "\n",
    "F√∂rst kontrollerar vi att milj√∂n √§r korrekt:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiet noisy ORT quantizer log line (appears even with correct preprocessing)\n",
    "import logging\n",
    "for name in (\"\", \"onnxruntime\", \"onnxruntime.quantization\"):\n",
    "    logging.getLogger(name).setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Changed working dir to repo root: C:\\Users\\olabl\\Documents\\GitHub\\piedge_edukit\n"
     ]
    }
   ],
   "source": [
    "# Make notebook run from repo root (not notebooks/ or labs/) + quiet mode\n",
    "import os, sys, warnings\n",
    "from pathlib import Path\n",
    "\n",
    "def cd_repo_root():\n",
    "    p = Path.cwd()\n",
    "    for _ in range(5):  # kl√§ttra upp√•t max 5 niv√•er\n",
    "        if (p/\"verify.py\").exists() and (p/\"scripts\"/\"evaluate_onnx.py\").exists():\n",
    "            if str(p) not in sys.path: sys.path.insert(0, str(p))\n",
    "            if p != Path.cwd():\n",
    "                os.chdir(p)\n",
    "                print(\"-> Changed working dir to repo root:\", os.getcwd())\n",
    "            return\n",
    "        p = p.parent\n",
    "    raise RuntimeError(\"Could not locate repo root\")\n",
    "\n",
    "cd_repo_root()\n",
    "\n",
    "# Quiet progress bars and some noisy warnings\n",
    "os.environ.setdefault(\"TQDM_DISABLE\", \"1\")  # hide tqdm progress bars\n",
    "os.environ.setdefault(\"PYTHONWARNINGS\", \"ignore\")\n",
    "os.environ.setdefault(\"ORT_LOG_SEVERITY_LEVEL\", \"3\")  # ORT info/warn -> quiet\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"onnxruntime\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa: E401\n",
    "# Cross-platform runner + live clock (no shell redirection needed)\n",
    "import sys\n",
    "import subprocess\n",
    "import time\n",
    "import threading\n",
    "import shutil\n",
    "from contextlib import contextmanager\n",
    "from IPython.display import display\n",
    "\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    _HAVE_WIDGETS = True\n",
    "except Exception:\n",
    "    _HAVE_WIDGETS = False\n",
    "\n",
    "@contextmanager\n",
    "def running_timer(label=\"Running‚Ä¶\"):\n",
    "    start = time.time()\n",
    "    symbols = [\"üïê\",\"üïë\",\"üïí\",\"üïì\",\"üïî\",\"üïï\",\"üïñ\",\"üïó\",\"üïò\",\"üïô\",\"üïö\",\"üïõ\"]\n",
    "    stop = False\n",
    "\n",
    "    if _HAVE_WIDGETS:\n",
    "        w = widgets.HTML()\n",
    "        display(w)\n",
    "        def _tick():\n",
    "            k = 0\n",
    "            while not stop:\n",
    "                w.value = f\"<b>{symbols[k%12]}</b> {label} &nbsp; <code>{time.time()-start:.1f}s</code>\"\n",
    "                time.sleep(0.5); k += 1\n",
    "        t = threading.Thread(target=_tick, daemon=True); t.start()\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            stop = True; t.join(timeout=0.2)\n",
    "            w.value = f\"‚úÖ Done ‚Äî <code>{time.time()-start:.1f}s</code>\"\n",
    "    else:\n",
    "        width = shutil.get_terminal_size((80, 20)).columns\n",
    "        def _tick():\n",
    "            k = 0\n",
    "            while not stop:\n",
    "                msg = f\"{symbols[k%12]} {label}  {time.time()-start:.1f}s\"\n",
    "                print(\"\\r\" + msg[:width].ljust(width), end=\"\")\n",
    "                time.sleep(0.5); k += 1\n",
    "            print()\n",
    "        t = threading.Thread(target=_tick, daemon=True); t.start()\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            stop = True; t.join(timeout=0.2)\n",
    "            print(f\"‚úÖ Done ‚Äî {time.time()-start:.1f}s\")\n",
    "\n",
    "def run_module(label, module, *args):\n",
    "    \"\"\"Run `python -m <module> <args>` cross-platform, capture output, raise on error.\"\"\"\n",
    "    with running_timer(label):\n",
    "        cmd = [sys.executable, \"-W\", \"ignore\", \"-m\", module, *map(str, args)]\n",
    "        proc = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "        print(proc.stdout)\n",
    "        if proc.returncode != 0:\n",
    "            raise RuntimeError(f\"{module} exited with code {proc.returncode}\")\n",
    "\n",
    "def run_script(label, path, *args):\n",
    "    \"\"\"Run `python <path> <args>` cross-platform, capture output, raise on error.\"\"\"\n",
    "    with running_timer(label):\n",
    "        cmd = [sys.executable, \"-W\", \"ignore\", path, *map(str, args)]\n",
    "        proc = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "        print(proc.stdout)\n",
    "        if proc.returncode != 0:\n",
    "            raise RuntimeError(f\"{path} exited with code {proc.returncode}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.10 (tags/v3.12.10:0cc8128, Apr  8 2025, 12:21:36) [MSC v.1943 64 bit (AMD64)]\n",
      "‚úÖ PiEdge EduKit package OK\n"
     ]
    }
   ],
   "source": [
    "# Milj√∂koll + sj√§lvl√§kning (Python 3.12 + editable install)\n",
    "import sys, os, importlib, subprocess\n",
    "print(f\"Python version: {sys.version}\")\n",
    "assert sys.version_info[:2] == (3, 12), f\"Python 3.12 kr√§vs, du har {sys.version_info[:2]}\"\n",
    "\n",
    "try:\n",
    "    import piedge_edukit  # noqa: F401\n",
    "    print(\"‚úÖ PiEdge EduKit package OK\")\n",
    "except ModuleNotFoundError:\n",
    "    # Hitta repo-roten: om vi st√•r i labs/, g√• ett steg upp\n",
    "    repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\")) if os.path.basename(os.getcwd()) == \"labs\" else os.getcwd()\n",
    "    print(\"‚ö† Package saknas ‚Äì installerar editable fr√•n:\", repo_root)\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", repo_root])\n",
    "    importlib.invalidate_caches()\n",
    "    import piedge_edukit  # noqa: F401\n",
    "    print(\"‚úÖ Package installerat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Paketet importeras ‚Äì k√∂r vidare!\n"
     ]
    }
   ],
   "source": [
    "# Paketet ska redan vara installerat av cellen ovan. Enkel sanity:\n",
    "import piedge_edukit\n",
    "print(\"‚úÖ Paketet importeras ‚Äì k√∂r vidare!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Tr√§ning & ONNX Export\n",
    "\n",
    "Tr√§nar en liten modell med FakeData och exporterar till ONNX:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49889c9cc0e433cb4e667b727284105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "[INFO] Using FakeData for training (no real images)\n",
      "Preparing data...\n",
      "Set 2 classes: ['class0', 'class1']\n",
      "Training model with 2 classes...\n",
      "Classes: ['class0', 'class1']\n",
      "\n",
      "Epoch 1/1\n",
      "Train Loss: 0.7062, Train Acc: 51.00%\n",
      "Val Loss: 0.6809, Val Acc: 65.00%\n",
      "\n",
      "Training completed! Best validation accuracy: 65.00%\n",
      "Exporting model to ONNX...\n",
      "[OK] Model exported to models\\model.onnx (opset 17)\n",
      "[OK] ONNX model verified successfully\n",
      "  Input shape: (1, 3, 64, 64)\n",
      "  Output shape: (1, 2)\n",
      "  Output dtype: float32\n",
      "[OK] Preprocessing configuration valid (hash: 9f9a96cb4a32eea9)\n",
      "[OK] Labels valid: 2 classes\n",
      "[OK] Model exported successfully to models\\model.onnx\n",
      "[OK] Training and export completed successfully!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tr√§na modell (snabb k√∂rning f√∂r demo)\n",
    "run_module(\"Training (FakeData)\",\n",
    "           \"piedge_edukit.train\",\n",
    "           \"--fakedata\", \"--no-pretrained\",\n",
    "           \"--epochs\", 1, \"--batch-size\", 256,\n",
    "           \"--output-dir\", \"./models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ONNX-modell skapad: 8.5 MB\n"
     ]
    }
   ],
   "source": [
    "# Kontrollera att modellen skapades\n",
    "import os\n",
    "if os.path.exists(\"./models/model.onnx\"):\n",
    "    size_mb = os.path.getsize(\"./models/model.onnx\") / (1024*1024)\n",
    "    print(f\"‚úÖ ONNX-modell skapad: {size_mb:.1f} MB\")\n",
    "else:\n",
    "    print(\"‚ùå ONNX-modell saknas\")\n",
    "\n",
    "# Visa tr√§ningsgrafer\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "\n",
    "training_plot = Path(\"reports/training_curves.png\")\n",
    "if training_plot.exists():\n",
    "    print(\"\\nüìà Tr√§ningsgrafer:\")\n",
    "    display(Image.open(training_plot))\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Tr√§ningsgrafer saknas ‚Äì k√∂r tr√§ningen f√∂rst.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Latensbenchmark\n",
    "\n",
    "M√§ter hur snabb modellen √§r p√• CPU:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d762dea75b744892b5fc3a8a57a61020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting latency benchmark...\n",
      "Model: models\\model.onnx\n",
      "Data: None\n",
      "Output: reports\n",
      "[OK] Model loaded successfully\n",
      "  Providers: ['CPUExecutionProvider']\n",
      "  Input shape: ['batch_size', 3, 64, 64]\n",
      "  Output shape: ['batch_size', 2]\n",
      "[INFO] Generating fake test data for benchmarking\n",
      "[OK] Generated 50 fake test images\n",
      "Running 1 warmup iterations...\n",
      "[OK] Warmup completed\n",
      "Running 3 benchmark iterations...\n",
      "[OK] Results saved to reports\n",
      "[OK] Plot saved to reports\\latency_plot.png\n",
      "\n",
      "==================================================\n",
      "BENCHMARK RESULTS\n",
      "==================================================\n",
      "Mean latency: 0.626 ms\n",
      "P50 latency:  0.648 ms\n",
      "P95 latency:  0.700 ms\n",
      "Std deviation: 0.076 ms\n",
      "==================================================\n",
      "\n",
      "[OK] Benchmark completed successfully!\n",
      "Results saved to: reports\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K√∂r benchmark (snabb k√∂rning)\n",
    "run_module(\"Benchmarking (CPU)\",\n",
    "           \"piedge_edukit.benchmark\",\n",
    "           \"--fakedata\",\n",
    "           \"--model-path\", \"./models/model.onnx\",\n",
    "           \"--warmup\", 1, \"--runs\", 3,\n",
    "           \"--providers\", \"CPUExecutionProvider\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Benchmark-resultat:\n",
      "PiEdge EduKit - Latency Benchmark Results\n",
      "==================================================\n",
      "\n",
      "Version: 0.1.0\n",
      "Generated: 2025-10-05 13:57:36\n",
      "\n",
      "Version Information:\n",
      "  Python: 3.12.10\n",
      "  ONNX Runtime: 1.18.0\n",
      "  Platform: Windows-11-10.0.26100-SP0\n",
      "  Device: PC/Laptop\n",
      "\n",
      "System Information:\n",
      "  cpu_count: 20\n",
      "  memory_gb: 63.39\n",
      "  piedge_edukit_version: 0.1.0\n",
      "  cpu_governor: N/A\n",
      "\n",
      "Benchmark Configuration:\n",
      "  Model: model.onnx\n",
      "  Warmup runs: 1\n",
      "  Benchmark runs: 3\n",
      "  Batch size: 1\n",
      "\n",
      "Latency Statistics (ms):\n",
      "  Mean: 0.626\n",
      "  Std:  0.076\n",
      "  Min:  0.524\n",
      "  Max:  0.706\n",
      "  P50:  0.648\n",
      "  P95:  0.700\n",
      "  P99:  0.705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visa benchmark-resultat\n",
    "if os.path.exists(\"./reports/latency_summary.txt\"):\n",
    "    with open(\"./reports/latency_summary.txt\", \"r\") as f:\n",
    "        print(\"üìä Benchmark-resultat:\")\n",
    "        print(f.read())\n",
    "else:\n",
    "    print(\"‚ùå Benchmark-rapport saknas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Kvantisering (INT8)\n",
    "\n",
    "Komprimerar modellen f√∂r snabbare inference:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Setting up calibration data (best practice: reuse real training images)\n",
      "‚úÖ Found 32 existing images in data\\train\n",
      "   Source: Real training data\n",
      "   ‚Üí Using --data-path ensures correct preprocessing (no ORT warning!)\n"
     ]
    }
   ],
   "source": [
    "# Best Practice: Use real training images for calibration\n",
    "# This ensures correct preprocessing and avoids ORT warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "print(\"üìä Setting up calibration data (best practice: reuse real training images)\")\n",
    "\n",
    "# Create tiny calibration image set if data/train/ is missing\n",
    "calib_dir = Path(\"data/train\")\n",
    "if not calib_dir.exists() or not any(calib_dir.rglob(\"*.png\")):\n",
    "    print(\"   Creating fallback calibration dataset...\")\n",
    "    for cls in [\"class0\", \"class1\"]:\n",
    "        (calib_dir / cls).mkdir(parents=True, exist_ok=True)\n",
    "        for i in range(16):  # 32 total (16 per class)\n",
    "            # Synthetic but \"real\" PNG files\n",
    "            arr = (np.random.rand(64, 64, 3) * 255).astype(np.uint8)\n",
    "            Image.fromarray(arr).save(calib_dir / cls / f\"sample_{i:02d}.png\")\n",
    "    print(f\"‚úÖ Created 32 fallback calibration images in {calib_dir}\")\n",
    "    print(f\"   Source: Synthetic PNG files (organized like real training data)\")\n",
    "else:\n",
    "    num_samples = sum(1 for p in calib_dir.rglob(\"*.png\"))\n",
    "    print(f\"‚úÖ Found {num_samples} existing images in {calib_dir}\")\n",
    "    print(f\"   Source: Real training data\")\n",
    "\n",
    "print(\"   ‚Üí Using --data-path ensures correct preprocessing (no ORT warning!)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d622ac06716e4555a505bd8236722f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n",
      "Starting quantization benchmark...\n",
      "FP32 Model: models\\model.onnx\n",
      "Data: data\\train\n",
      "Output: reports\n",
      "[OK] Preprocessing configuration valid (hash: 9f9a96cb4a32eea9)\n",
      "[OK] Labels valid: 2 classes\n",
      "Found 32 calibration images\n",
      "Preprocessed 32 calibration images\n",
      "Quantizing model to INT8...\n",
      "[ERROR] Quantization failed: 'list' object has no attribute 'get_next'\n",
      "This may be due to unsupported operations or ONNX Runtime version.\n",
      "Continuing with FP32 model only.\n",
      "\n",
      "Benchmarking FP32 model...\n",
      "Benchmarking FP32 model...\n",
      "Benchmarking FP32 model...\n",
      "\n",
      "Skipping INT8 benchmarking (quantization failed)\n",
      "[OK] Comparison results saved to reports\n",
      "[OK] Comparison plot saved to reports\\quantization_comparison.png\n",
      "\n",
      "============================================================\n",
      "QUANTIZATION BENCHMARK RESULTS\n",
      "============================================================\n",
      "Quantization Status: FAILED\n",
      "Error: INT8 quantization failed - continuing with FP32 only\n",
      "FP32 Latency: 0.601 ms\n",
      "FP32 Size: 8.47 MB\n",
      "============================================================\n",
      "\n",
      "[OK] Quantization benchmark completed successfully!\n",
      "Results saved to: reports\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K√∂r kvantisering med RIKTIGA tr√§ningsbilder (korrekt preprocessing, ingen ORT-varning!)\n",
    "try:\n",
    "    if calib_dir.exists():\n",
    "        # Use real training data - same preprocessing as model was trained with\n",
    "        run_module(\"Quantization (INT8 with real calibration data)\",\n",
    "                   \"piedge_edukit.quantization\",\n",
    "                   \"--data-path\", str(calib_dir),\n",
    "                   \"--model-path\", \"./models/model.onnx\",\n",
    "                   \"--calib-size\", 32)\n",
    "    else:\n",
    "        # Fallback to FakeData (will show ORT warning)\n",
    "        run_module(\"Quantization (INT8 attempt with FakeData)\",\n",
    "                   \"piedge_edukit.quantization\",\n",
    "                   \"--fakedata\",\n",
    "                   \"--model-path\", \"./models/model.onnx\",\n",
    "                   \"--calib-size\", 16)\n",
    "except RuntimeError as e:\n",
    "    print(\"‚ö†Ô∏è Quantization step failed (OK for demo):\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Kvantiseringsresultat:\n",
      "PiEdge EduKit - Quantization Comparison Results\n",
      "============================================================\n",
      "\n",
      "Version: 0.1.0\n",
      "Generated: 2025-10-05 13:57:53\n",
      "\n",
      "Model Comparison:\n",
      "  FP32 Size: 8.47 MB\n",
      "  INT8 Size: N/A (quantization failed)\n",
      "  Size Reduction: N/A (quantization failed)\n",
      "\n",
      "Latency Comparison:\n",
      "  FP32 Mean: 0.601 ms\n",
      "  INT8 Mean: N/A (quantization failed)\n",
      "  Speedup: N/A (quantization failed)\n",
      "\n",
      "Accuracy Comparison: N/A (quantization failed)\n",
      "\n",
      "\n",
      "‚ÑπÔ∏è INT8-kvantisering kan fallera p√• vissa milj√∂er. I denna lektion √§r **FP32** godk√§nt; verify accepterar fallback.\n"
     ]
    }
   ],
   "source": [
    "# Visa kvantiseringsresultat\n",
    "if os.path.exists(\"./reports/quantization_summary.txt\"):\n",
    "    with open(\"./reports/quantization_summary.txt\", \"r\") as f:\n",
    "        print(\"‚ö° Kvantiseringsresultat:\")\n",
    "        print(f.read())\n",
    "else:\n",
    "    print(\"‚ùå Kvantiseringsrapport saknas\")\n",
    "\n",
    "# Tydlig notis om INT8-fail\n",
    "print(\"\\n‚ÑπÔ∏è INT8-kvantisering kan fallera p√• vissa milj√∂er. I denna lektion √§r **FP32** godk√§nt; verify accepterar fallback.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Utv√§rdering & Verifiering\n",
    "\n",
    "Testar modellen och genererar kvitto:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a67df199c90454eadbd23c13c73884b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote reports/confusion_matrix.png and reports/eval_summary.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K√∂r utv√§rdering\n",
    "from pathlib import Path\n",
    "\n",
    "run_script(\"Evaluating ONNX\",\n",
    "           str(Path(\"scripts/evaluate_onnx.py\").resolve()),\n",
    "           \"--model\", \"./models/model.onnx\",\n",
    "           \"--fakedata\", \"--limit\", 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a1caec8ea324b9bbef89773b3ac77d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K√∂r verifiering och generera kvitto\n",
    "from pathlib import Path\n",
    "\n",
    "run_script(\"Verifying & generating receipt\", str(Path(\"verify.py\").resolve()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Verifieringskvitto:\n",
      "Status: ‚úÖ PASS\n",
      "Timestamp: 2025-10-05T11:58:05.403403+00:00\n",
      "\n",
      "Kontroller:\n",
      "  ‚úÖ artifacts_exist: All required artifacts present\n",
      "  ‚úÖ latency_summary_parse: Successfully parsed latency metrics\n",
      "  ‚úÖ quantization_report_exists: Quantization report exists\n",
      "  ‚úÖ quant_speedup_or_fallback: INT8 quantization failed - fallback accepted\n",
      "  ‚úÖ evaluation_reports_exist: Evaluation reports present\n"
     ]
    }
   ],
   "source": [
    "# Visa kvitto\n",
    "import json\n",
    "if os.path.exists(\"./progress/receipt.json\"):\n",
    "    with open(\"./progress/receipt.json\", \"r\") as f:\n",
    "        receipt = json.load(f)\n",
    "    print(\"üìã Verifieringskvitto:\")\n",
    "    print(f\"Status: {'‚úÖ PASS' if receipt['pass'] else '‚ùå FAIL'}\")\n",
    "    print(f\"Timestamp: {receipt['timestamp']}\")\n",
    "    print(\"\\nKontroller:\")\n",
    "    for check in receipt['checks']:\n",
    "        status = \"‚úÖ\" if check['ok'] else \"‚ùå\"\n",
    "        print(f\"  {status} {check['name']}: {check['reason']}\")\n",
    "else:\n",
    "    print(\"‚ùå Kvitto saknas\")\n",
    "\n",
    "# Visa confusion matrix\n",
    "confusion_plot = Path(\"reports/confusion_matrix.png\")\n",
    "if confusion_plot.exists():\n",
    "    print(\"\\nüìä Confusion Matrix:\")\n",
    "    display(Image.open(confusion_plot))\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Confusion matrix saknas ‚Äì k√∂r utv√§rderingen f√∂rst.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Klar!\n",
    "\n",
    "Du har nu k√∂rt hela PiEdge EduKit-lektionen! \n",
    "\n",
    "**N√§sta steg**: G√• till `01_training_and_export.ipynb` f√∂r att f√∂rst√• vad som h√§nde under tr√§ningen.\n",
    "\n",
    "**Genererade filer**:\n",
    "- `models/model.onnx` - Tr√§nad modell\n",
    "- `reports/` - Benchmark och kvantiseringsrapporter\n",
    "- `progress/receipt.json` - Verifieringskvitto\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Forts√§tt med detaljerade lektioner\n",
    "\n",
    "**‚≠ê Rekommenderad ordning**:\n",
    "1. **`01_training_and_export.ipynb`** - F√∂rst√• tr√§ning och ONNX-export\n",
    "2. **`02_latency_benchmark.ipynb`** - L√§r dig m√§ta prestanda\n",
    "3. **`03_quantization.ipynb`** - Komprimera modeller f√∂r edge\n",
    "4. **`04_evaluate_and_verify.ipynb`** - Utv√§rdera och verifiera resultat\n",
    "\n",
    "**üí° Tips**: Varje notebook bygger p√• f√∂reg√•ende - k√∂r dem i ordning f√∂r b√§sta l√§rande!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-Glossary\n",
    "\n",
    "* **ONNX**: portable model format defined as an operator graph.\n",
    "* **Opset**: versioned set of operators supported by runtimes.\n",
    "* **Execution Provider (EP)**: backend used by ONNX Runtime (CPU, CUDA, DirectML‚Ä¶).\n",
    "* **Latency**: time per request; **Throughput**: requests per second.\n",
    "* **P50/P95/P99**: latency percentiles; tails indicate rare slow requests.\n",
    "* **Quantization (PTQ)**: convert FP32 to INT8 using calibration data.\n",
    "* **Calibration**: running representative samples to estimate activation ranges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (piedge)",
   "language": "python",
   "name": "piedge-edukit-312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
