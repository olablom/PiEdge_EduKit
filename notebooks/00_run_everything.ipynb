{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ PiEdge EduKit - Quick Run & Sanity Check\n",
    "\n",
    "## What you'll learn today\n",
    "\n",
    "* Train a tiny image classifier in PyTorch\n",
    "* Export the model to **ONNX** (a portable format for deployment)\n",
    "* Measure inference latency and interpret P50/P95\n",
    "* (Try to) quantize to INT8 and understand why it may fail\n",
    "* Evaluate the model and record a reproducible \"receipt\"\n",
    "\n",
    "## Why this matters\n",
    "\n",
    "Most real projects train in Python but deploy elsewhere (C++, mobile, web, embedded). ONNX lets us move models **out of Python** without rewriting the model by hand.\n",
    "\n",
    "## How to use this notebook\n",
    "\n",
    "This is a **smoke test**: it runs the whole pipeline end-to-end so your environment is correct. For learning and coding tasks, continue with **`01_training_and_export.ipynb`** ‚Üí **`04_evaluate_and_verify.ipynb`**.\n",
    "\n",
    "---\n",
    "\n",
    "## ONNX 101\n",
    "\n",
    "**What is ONNX?**\n",
    "ONNX (Open Neural Network Exchange) is an **open standard** for representing ML models as a graph of operators (Conv, Relu, MatMul‚Ä¶). Many frameworks can **export** to ONNX (PyTorch, TensorFlow) and many runtimes can **execute** ONNX (ONNX Runtime, TensorRT, CoreML Tools).\n",
    "\n",
    "**Why ONNX?**\n",
    "\n",
    "* **Portability**: train in Python, deploy in C++/C#/Java/JS, mobile or edge.\n",
    "* **Performance**: runtimes fuse ops and call optimized backends (MKL, cuDNN).\n",
    "* **Interoperability**: one model file can run across platforms with different \"Execution Providers\" (CPU, CUDA, DirectML, NNAPI‚Ä¶).\n",
    "\n",
    "**Key terms**\n",
    "\n",
    "* **Opset**: version of the operator set supported by runtimes. We export with a specific opset (e.g., 17).\n",
    "* **Static vs dynamic shapes**: fixed sizes are simpler/faster; dynamic adds flexibility.\n",
    "* **Execution Provider (EP)**: the backend used by ONNX Runtime (e.g., `CPUExecutionProvider`).\n",
    "* **Pre/Post-processing**: steps around the model (resize, normalize, label mapping). These **aren't** part of the ONNX graph; the app must do the same steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup & Verifiering\n",
    "\n",
    "F√∂rst kontrollerar vi att milj√∂n √§r korrekt:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiet noisy ORT quantizer log line (appears even with correct preprocessing)\n",
    "import logging\n",
    "for name in (\"\", \"onnxruntime\", \"onnxruntime.quantization\"):\n",
    "    logging.getLogger(name).setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make notebook run from repo root (not labs/) + quiet mode\n",
    "import os, sys, warnings, pathlib\n",
    "\n",
    "# If opened from labs/, change working directory to repo root\n",
    "nb_dir = pathlib.Path.cwd()\n",
    "if nb_dir.name == \"labs\":\n",
    "    os.chdir(nb_dir.parent)\n",
    "    print(\"-> Changed working dir to repo root:\", os.getcwd())\n",
    "\n",
    "# Ensure repo root is importable\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.insert(0, os.getcwd())\n",
    "\n",
    "# Quiet progress bars and some noisy warnings\n",
    "os.environ.setdefault(\"TQDM_DISABLE\", \"1\")  # hide tqdm progress bars\n",
    "os.environ.setdefault(\"PYTHONWARNINGS\", \"ignore\")\n",
    "os.environ.setdefault(\"ORT_LOG_SEVERITY_LEVEL\", \"3\")  # ORT info/warn -> quiet\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"onnxruntime\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa: E401\n",
    "# Cross-platform runner + live clock (no shell redirection needed)\n",
    "import sys\n",
    "import subprocess\n",
    "import time\n",
    "import threading\n",
    "import shutil\n",
    "from contextlib import contextmanager\n",
    "from IPython.display import display\n",
    "\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    _HAVE_WIDGETS = True\n",
    "except Exception:\n",
    "    _HAVE_WIDGETS = False\n",
    "\n",
    "@contextmanager\n",
    "def running_timer(label=\"Running‚Ä¶\"):\n",
    "    start = time.time()\n",
    "    symbols = [\"üïê\",\"üïë\",\"üïí\",\"üïì\",\"üïî\",\"üïï\",\"üïñ\",\"üïó\",\"üïò\",\"üïô\",\"üïö\",\"üïõ\"]\n",
    "    stop = False\n",
    "\n",
    "    if _HAVE_WIDGETS:\n",
    "        w = widgets.HTML()\n",
    "        display(w)\n",
    "        def _tick():\n",
    "            k = 0\n",
    "            while not stop:\n",
    "                w.value = f\"<b>{symbols[k%12]}</b> {label} &nbsp; <code>{time.time()-start:.1f}s</code>\"\n",
    "                time.sleep(0.5); k += 1\n",
    "        t = threading.Thread(target=_tick, daemon=True); t.start()\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            stop = True; t.join(timeout=0.2)\n",
    "            w.value = f\"‚úÖ Done ‚Äî <code>{time.time()-start:.1f}s</code>\"\n",
    "    else:\n",
    "        width = shutil.get_terminal_size((80, 20)).columns\n",
    "        def _tick():\n",
    "            k = 0\n",
    "            while not stop:\n",
    "                msg = f\"{symbols[k%12]} {label}  {time.time()-start:.1f}s\"\n",
    "                print(\"\\r\" + msg[:width].ljust(width), end=\"\")\n",
    "                time.sleep(0.5); k += 1\n",
    "            print()\n",
    "        t = threading.Thread(target=_tick, daemon=True); t.start()\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            stop = True; t.join(timeout=0.2)\n",
    "            print(f\"‚úÖ Done ‚Äî {time.time()-start:.1f}s\")\n",
    "\n",
    "def run_module(label, module, *args):\n",
    "    \"\"\"Run `python -m <module> <args>` cross-platform, capture output, raise on error.\"\"\"\n",
    "    with running_timer(label):\n",
    "        cmd = [sys.executable, \"-W\", \"ignore\", \"-m\", module, *map(str, args)]\n",
    "        proc = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "        print(proc.stdout)\n",
    "        if proc.returncode != 0:\n",
    "            raise RuntimeError(f\"{module} exited with code {proc.returncode}\")\n",
    "\n",
    "def run_script(label, path, *args):\n",
    "    \"\"\"Run `python <path> <args>` cross-platform, capture output, raise on error.\"\"\"\n",
    "    with running_timer(label):\n",
    "        cmd = [sys.executable, \"-W\", \"ignore\", path, *map(str, args)]\n",
    "        proc = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "        print(proc.stdout)\n",
    "        if proc.returncode != 0:\n",
    "            raise RuntimeError(f\"{path} exited with code {proc.returncode}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Milj√∂koll + sj√§lvl√§kning (Python 3.12 + editable install)\n",
    "import sys, os, importlib, subprocess\n",
    "print(f\"Python version: {sys.version}\")\n",
    "assert sys.version_info[:2] == (3, 12), f\"Python 3.12 kr√§vs, du har {sys.version_info[:2]}\"\n",
    "\n",
    "try:\n",
    "    import piedge_edukit  # noqa: F401\n",
    "    print(\"‚úÖ PiEdge EduKit package OK\")\n",
    "except ModuleNotFoundError:\n",
    "    # Hitta repo-roten: om vi st√•r i labs/, g√• ett steg upp\n",
    "    repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\")) if os.path.basename(os.getcwd()) == \"labs\" else os.getcwd()\n",
    "    print(\"‚ö† Package saknas ‚Äì installerar editable fr√•n:\", repo_root)\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", repo_root])\n",
    "    importlib.invalidate_caches()\n",
    "    import piedge_edukit  # noqa: F401\n",
    "    print(\"‚úÖ Package installerat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paketet ska redan vara installerat av cellen ovan. Enkel sanity:\n",
    "import piedge_edukit\n",
    "print(\"‚úÖ Paketet importeras ‚Äì k√∂r vidare!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Tr√§ning & ONNX Export\n",
    "\n",
    "Tr√§nar en liten modell med FakeData och exporterar till ONNX:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tr√§na modell (snabb k√∂rning f√∂r demo)\n",
    "run_module(\"Training (FakeData)\",\n",
    "           \"piedge_edukit.train\",\n",
    "           \"--fakedata\", \"--no-pretrained\",\n",
    "           \"--epochs\", 1, \"--batch-size\", 256,\n",
    "           \"--output-dir\", \"./models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kontrollera att modellen skapades\n",
    "import os\n",
    "if os.path.exists(\"./models/model.onnx\"):\n",
    "    size_mb = os.path.getsize(\"./models/model.onnx\") / (1024*1024)\n",
    "    print(f\"‚úÖ ONNX-modell skapad: {size_mb:.1f} MB\")\n",
    "else:\n",
    "    print(\"‚ùå ONNX-modell saknas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Latensbenchmark\n",
    "\n",
    "M√§ter hur snabb modellen √§r p√• CPU:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K√∂r benchmark (snabb k√∂rning)\n",
    "run_module(\"Benchmarking (CPU)\",\n",
    "           \"piedge_edukit.benchmark\",\n",
    "           \"--fakedata\",\n",
    "           \"--model-path\", \"./models/model.onnx\",\n",
    "           \"--warmup\", 1, \"--runs\", 3,\n",
    "           \"--providers\", \"CPUExecutionProvider\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visa benchmark-resultat\n",
    "if os.path.exists(\"./reports/latency_summary.txt\"):\n",
    "    with open(\"./reports/latency_summary.txt\", \"r\") as f:\n",
    "        print(\"üìä Benchmark-resultat:\")\n",
    "        print(f.read())\n",
    "else:\n",
    "    print(\"‚ùå Benchmark-rapport saknas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Kvantisering (INT8)\n",
    "\n",
    "Komprimerar modellen f√∂r snabbare inference:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Practice: Use real training images for calibration\n",
    "# This ensures correct preprocessing and avoids ORT warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "print(\"üìä Setting up calibration data (best practice: reuse real training images)\")\n",
    "\n",
    "# Create tiny calibration image set if data/train/ is missing\n",
    "calib_dir = Path(\"data/train\")\n",
    "if not calib_dir.exists() or not any(calib_dir.rglob(\"*.png\")):\n",
    "    print(\"   Creating fallback calibration dataset...\")\n",
    "    for cls in [\"class0\", \"class1\"]:\n",
    "        (calib_dir / cls).mkdir(parents=True, exist_ok=True)\n",
    "        for i in range(16):  # 32 total (16 per class)\n",
    "            # Synthetic but \"real\" PNG files\n",
    "            arr = (np.random.rand(64, 64, 3) * 255).astype(np.uint8)\n",
    "            Image.fromarray(arr).save(calib_dir / cls / f\"sample_{i:02d}.png\")\n",
    "    print(f\"‚úÖ Created 32 fallback calibration images in {calib_dir}\")\n",
    "    print(f\"   Source: Synthetic PNG files (organized like real training data)\")\n",
    "else:\n",
    "    num_samples = sum(1 for p in calib_dir.rglob(\"*.png\"))\n",
    "    print(f\"‚úÖ Found {num_samples} existing images in {calib_dir}\")\n",
    "    print(f\"   Source: Real training data\")\n",
    "\n",
    "print(\"   ‚Üí Using --data-path ensures correct preprocessing (no ORT warning!)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K√∂r kvantisering med RIKTIGA tr√§ningsbilder (korrekt preprocessing, ingen ORT-varning!)\n",
    "try:\n",
    "    if calib_dir.exists():\n",
    "        # Use real training data - same preprocessing as model was trained with\n",
    "        run_module(\"Quantization (INT8 with real calibration data)\",\n",
    "                   \"piedge_edukit.quantization\",\n",
    "                   \"--data-path\", str(calib_dir),\n",
    "                   \"--model-path\", \"./models/model.onnx\",\n",
    "                   \"--calib-size\", 32)\n",
    "    else:\n",
    "        # Fallback to FakeData (will show ORT warning)\n",
    "        run_module(\"Quantization (INT8 attempt with FakeData)\",\n",
    "                   \"piedge_edukit.quantization\",\n",
    "                   \"--fakedata\",\n",
    "                   \"--model-path\", \"./models/model.onnx\",\n",
    "                   \"--calib-size\", 16)\n",
    "except RuntimeError as e:\n",
    "    print(\"‚ö†Ô∏è Quantization step failed (OK for demo):\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visa kvantiseringsresultat\n",
    "if os.path.exists(\"./reports/quantization_summary.txt\"):\n",
    "    with open(\"./reports/quantization_summary.txt\", \"r\") as f:\n",
    "        print(\"‚ö° Kvantiseringsresultat:\")\n",
    "        print(f.read())\n",
    "else:\n",
    "    print(\"‚ùå Kvantiseringsrapport saknas\")\n",
    "\n",
    "# Tydlig notis om INT8-fail\n",
    "print(\"\\n‚ÑπÔ∏è INT8-kvantisering kan fallera p√• vissa milj√∂er. I denna lektion √§r **FP32** godk√§nt; verify accepterar fallback.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Utv√§rdering & Verifiering\n",
    "\n",
    "Testar modellen och genererar kvitto:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K√∂r utv√§rdering\n",
    "run_script(\"Evaluating ONNX\",\n",
    "           \"scripts/evaluate_onnx.py\",\n",
    "           \"--model\", \"./models/model.onnx\",\n",
    "           \"--fakedata\", \"--limit\", 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K√∂r verifiering och generera kvitto\n",
    "run_script(\"Verifying & generating receipt\", \"verify.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visa kvitto\n",
    "import json\n",
    "if os.path.exists(\"./progress/receipt.json\"):\n",
    "    with open(\"./progress/receipt.json\", \"r\") as f:\n",
    "        receipt = json.load(f)\n",
    "    print(\"üìã Verifieringskvitto:\")\n",
    "    print(f\"Status: {'‚úÖ PASS' if receipt['pass'] else '‚ùå FAIL'}\")\n",
    "    print(f\"Timestamp: {receipt['timestamp']}\")\n",
    "    print(\"\\nKontroller:\")\n",
    "    for check in receipt['checks']:\n",
    "        status = \"‚úÖ\" if check['ok'] else \"‚ùå\"\n",
    "        print(f\"  {status} {check['name']}: {check['reason']}\")\n",
    "else:\n",
    "    print(\"‚ùå Kvitto saknas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Klar!\n",
    "\n",
    "Du har nu k√∂rt hela PiEdge EduKit-lektionen! \n",
    "\n",
    "**N√§sta steg**: G√• till `01_training_and_export.ipynb` f√∂r att f√∂rst√• vad som h√§nde under tr√§ningen.\n",
    "\n",
    "**Genererade filer**:\n",
    "- `models/model.onnx` - Tr√§nad modell\n",
    "- `reports/` - Benchmark och kvantiseringsrapporter\n",
    "- `progress/receipt.json` - Verifieringskvitto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-Glossary\n",
    "\n",
    "* **ONNX**: portable model format defined as an operator graph.\n",
    "* **Opset**: versioned set of operators supported by runtimes.\n",
    "* **Execution Provider (EP)**: backend used by ONNX Runtime (CPU, CUDA, DirectML‚Ä¶).\n",
    "* **Latency**: time per request; **Throughput**: requests per second.\n",
    "* **P50/P95/P99**: latency percentiles; tails indicate rare slow requests.\n",
    "* **Quantization (PTQ)**: convert FP32 to INT8 using calibration data.\n",
    "* **Calibration**: running representative samples to estimate activation ranges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (piedge)",
   "language": "python",
   "name": "piedge-edukit-312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
