{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 - Training & Export\n",
        "\n",
        "## Learning Goals\n",
        "\n",
        "* Understand the pieces of a PyTorch training loop (model → loss → optimizer → data loader → epochs).\n",
        "* Implement/inspect a tiny CNN and see how accuracy changes with hyper-parameters.\n",
        "* Export to ONNX and verify the file loads and produces outputs of the right shape/dtype.\n",
        "\n",
        "## You Should Be Able To...\n",
        "\n",
        "- Implement a basic CNN using PyTorch layers\n",
        "- Write a training loop with loss calculation and accuracy tracking\n",
        "- Export a trained model to ONNX format with proper input/output specifications\n",
        "- Explain why ONNX export is useful for edge deployment\n",
        "- Identify key hyperparameters that affect model performance\n",
        "\n",
        "---\n",
        "\n",
        "## Concepts\n",
        "\n",
        "**Training loop**: forward → compute loss → backward → optimizer step → repeat.\n",
        "\n",
        "**Evaluation mode**: `model.eval()` disables dropout/batchnorm updates for deterministic inference.\n",
        "\n",
        "**Export to ONNX**: we trace the model with a sample input and save `models/model.onnx`.\n",
        "\n",
        "**Preprocessing contract**: whatever normalization/resizing you used during training **must be used at inference** (outside the ONNX graph).\n",
        "\n",
        "## Common Pitfalls\n",
        "\n",
        "* Forgetting `model.eval()` before export (exporting training behavior).\n",
        "* Mismatch between training normalization and inference normalization (bad accuracy).\n",
        "* Exporting with the wrong input shape.\n",
        "\n",
        "## Success Criteria\n",
        "\n",
        "* ✅ Training runs and prints accuracy\n",
        "* ✅ `models/model.onnx` exists and can be loaded\n",
        "* ✅ Checker says shapes/dtypes are valid\n",
        "\n",
        "---\n",
        "\n",
        "## Setup & Environment Check\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ruff: noqa: E401\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Ensure repo root in path if opened from labs/\n",
        "if Path.cwd().name == \"labs\":\n",
        "    os.chdir(Path.cwd().parent)\n",
        "    print(\"→ Working dir set to repo root:\", os.getcwd())\n",
        "if os.getcwd() not in sys.path:\n",
        "    sys.path.insert(0, os.getcwd())\n",
        "\n",
        "# Core deps\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import onnx\n",
        "from onnx import checker  # noqa: F401\n",
        "import onnxruntime as ort  # noqa: F401\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.datasets import FakeData as TVFakeData\n",
        "\n",
        "# Project package\n",
        "from piedge_edukit.preprocess import FakeData as PEDFakeData\n",
        "\n",
        "# Hints & Solutions helper (pure Jupyter, no extra deps)\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "def hints(*lines, solution: str | None = None, title=\"Need a nudge?\"):\n",
        "    \"\"\"Render progressive hints + optional collapsible solution.\"\"\"\n",
        "    md = [f\"### {title}\"]\n",
        "    for i, txt in enumerate(lines, start=1):\n",
        "        md.append(f\"<details><summary>Hint {i}</summary>\\n\\n{txt}\\n\\n</details>\")\n",
        "    if solution:\n",
        "        # keep code fenced as python for readability\n",
        "        md.append(\n",
        "            \"<details><summary><b>Show solution</b></summary>\\n\\n\"\n",
        "            f\"```python\\n{solution.strip()}\\n```\\n\"\n",
        "            \"</details>\"\n",
        "        )\n",
        "    display(Markdown(\"\\n\\n\".join(md)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Environment self-heal (Python 3.12 + editable install)\n",
        "import subprocess\n",
        "import importlib\n",
        "\n",
        "print(f\"Python: {sys.version.split()[0]} (need 3.12)\")\n",
        "\n",
        "try:\n",
        "    import piedge_edukit  # noqa: F401\n",
        "    print(\"✅ PiEdge EduKit package OK\")\n",
        "except ModuleNotFoundError:\n",
        "    print(\"ℹ️ Installing package in editable mode …\")\n",
        "    root = os.getcwd()\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", root])\n",
        "    importlib.invalidate_caches()\n",
        "    import piedge_edukit  # noqa: F401\n",
        "    print(\"✅ Package installed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# All imports are now in the first cell above\n",
        "print(\"✅ All imports successful\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Concept: Convolutional Neural Networks\n",
        "\n",
        "CNNs are designed to process grid-like data (images) by:\n",
        "- **Convolutional layers**: Learn spatial patterns (edges, textures, shapes)\n",
        "- **Pooling layers**: Reduce spatial dimensions while preserving important features\n",
        "- **Fully connected layers**: Make final classification decisions\n",
        "\n",
        "For 64×64 RGB images, a typical architecture flows: `[3,64,64] → Conv → ReLU → Pool → Conv → ReLU → Pool → Flatten → Linear → Linear → [num_classes]`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task A: Implement a Simple CNN\n",
        "\n",
        "Your task is to implement a `TinyCNN` class that can classify 64×64 RGB images into 2 classes.\n",
        "\n",
        "### TODO A1 — Implement `TinyCNN`\n",
        "**Goal:** Build a minimal Conv → ReLU → MaxPool stack ending in a linear head.\n",
        "\n",
        "<details><summary>Hint 1</summary>\n",
        "Start with 3×3 conv, stride=1, padding=1. Use MaxPool 2×2 to downsample.\n",
        "</details>\n",
        "\n",
        "<details><summary>Hint 2</summary>\n",
        "Two conv blocks are enough for FakeData. Flatten before the linear layer.\n",
        "</details>\n",
        "\n",
        "<details><summary>Hint 3</summary>\n",
        "`forward(x)` should return logits (no softmax).\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "import torch.nn as nn\n",
        "\n",
        "class TinyCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.head = nn.Linear(32*8*8, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.head(x)\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO A1: implement TinyCNN here (or edit if already stubbed)\n",
        "\n",
        "# Create model instance\n",
        "model = TinyCNN(num_classes=2)\n",
        "print(f\"Model created with {sum(p.numel() for p in model.parameters())} parameters\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TEST: model should accept [1,3,64,64] and output [1,2]\n",
        "# (torch already imported in first cell)\n",
        "x = torch.randn(1,3,64,64)\n",
        "y = model(x)\n",
        "assert y.shape == (1,2), f\"Expected (1,2), got {tuple(y.shape)}\"\n",
        "print(\"✅ Shape test passed\")\n",
        "print(f\"Input shape: {x.shape}\")\n",
        "print(f\"Output shape: {y.shape}\")\n",
        "print(f\"Output range: [{y.min().item():.3f}, {y.max().item():.3f}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Concept: Training Loop Components\n",
        "\n",
        "A typical training loop includes:\n",
        "1. **Forward pass**: Compute predictions\n",
        "2. **Loss calculation**: Compare predictions to ground truth\n",
        "3. **Backward pass**: Compute gradients\n",
        "4. **Optimizer step**: Update model parameters\n",
        "5. **Metrics tracking**: Monitor loss and accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task B: Write the Training Step\n",
        "\n",
        "Implement a `train_one_epoch` function that trains the model for one epoch and returns loss and accuracy metrics.\n",
        "\n",
        "### TODO B1 — Implement one training step\n",
        "**Goal:** zero_grad → forward → compute loss → backward → step\n",
        "\n",
        "<details><summary>Hint 1</summary>\n",
        "`optimizer.zero_grad()` måste kallas före `loss.backward()`.\n",
        "</details>\n",
        "\n",
        "<details><summary>Hint 2</summary>\n",
        "Använd `model.train()` under träning.\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def train_step(model, batch, optimizer, criterion):\n",
        "    model.train()\n",
        "    x, y = batch\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(x)\n",
        "    loss = criterion(logits, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss.detach().cpu())\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO B1: implement train_step(...)\n",
        "\n",
        "# Test the function signature\n",
        "print(\"✅ Function signature looks correct\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create test data and test the training function\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Create fake data loader\n",
        "fake_data = FakeData(num_samples=100, image_size=64, num_classes=2)\n",
        "train_loader = DataLoader(fake_data, batch_size=16, shuffle=True)\n",
        "\n",
        "# Create optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Test training function\n",
        "metrics = train_one_epoch(model, train_loader, optimizer, device)\n",
        "assert \"loss\" in metrics and \"acc\" in metrics\n",
        "print(\"✅ Training loop smoke test passed\")\n",
        "print(f\"Loss: {metrics['loss']:.4f}, Accuracy: {metrics['acc']:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Concept: ONNX Export\n",
        "\n",
        "ONNX (Open Neural Network Exchange) is a format that allows models to run on different platforms:\n",
        "- **Cross-platform**: Same model runs on CPU, GPU, mobile, edge devices\n",
        "- **Optimized inference**: ONNX Runtime provides optimized execution\n",
        "- **Language agnostic**: Models can be used from Python, C++, C#, JavaScript, etc.\n",
        "\n",
        "Key requirements for export:\n",
        "- Model must be in evaluation mode (`model.eval()`)\n",
        "- Provide a dummy input with correct shape\n",
        "- Specify input/output names for clarity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task C: Export to ONNX\n",
        "\n",
        "Export your trained model to ONNX format for edge deployment.\n",
        "\n",
        "### TODO C1 — Export to ONNX with dynamic axes\n",
        "**Goal:** Put model in `eval()`, feed a dummy input, export to `models/model.onnx`.\n",
        "\n",
        "<details><summary>Hint 1</summary>\n",
        "Use `torch.onnx.export(model, dummy, \"models/model.onnx\", opset_version=17, dynamic_axes=...)`.\n",
        "</details>\n",
        "\n",
        "<details><summary>Hint 2</summary>\n",
        "`dynamic_axes={\"input\": {0: \"batch\"}, \"output\": {0: \"batch\"}}`.\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "import torch, os\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "model.eval()\n",
        "dummy = torch.randn(1, 3, 32, 32)\n",
        "torch.onnx.export(\n",
        "    model, dummy, \"models/model.onnx\",\n",
        "    input_names=[\"input\"], output_names=[\"output\"],\n",
        "    dynamic_axes={\"input\": {0: \"batch\"}, \"output\": {0: \"batch\"}},\n",
        "    opset_version=17\n",
        ")\n",
        "print(\"[OK] Exported to models/model.onnx\")\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO C1: export ONNX here\n",
        "\n",
        "print(\"✅ ONNX export completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test ONNX export\n",
        "# (onnx and os already imported in first cell)\n",
        "assert os.path.exists(\"./models/model.onnx\"), \"ONNX file missing\"\n",
        "m = onnx.load(\"./models/model.onnx\")\n",
        "onnx.checker.check_model(m)\n",
        "print(\"✅ ONNX export verified\")\n",
        "\n",
        "# Show model info\n",
        "file_size = os.path.getsize(\"./models/model.onnx\") / (1024*1024)\n",
        "print(f\"Model size: {file_size:.2f} MB\")\n",
        "print(f\"Input shape: {[d.dim_value for d in m.graph.input[0].type.tensor_type.shape.dim]}\")\n",
        "print(f\"Output shape: {[d.dim_value for d in m.graph.output[0].type.tensor_type.shape.dim]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection Questions\n",
        "\n",
        "Please answer these questions in 2-3 sentences each:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**1. What two hyperparameters most affected your validation accuracy? Why?**\n",
        "\n",
        "*Your answer here (2-3 sentences):*\n",
        "\n",
        "---\n",
        "\n",
        "**2. Why is exporting to ONNX useful for edge deployment?**\n",
        "\n",
        "*Your answer here (2-3 sentences):*\n",
        "\n",
        "---\n",
        "\n",
        "**3. What would happen if you forgot to call `model.eval()` before ONNX export?**\n",
        "\n",
        "*Your answer here (2-3 sentences):*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "Great work! You've implemented a CNN, trained it, and exported it to ONNX format.\n",
        "\n",
        "**Next**: Open `02_latency_benchmark.ipynb` to learn about performance measurement and optimization.\n",
        "\n",
        "---\n",
        "\n",
        "### Summary\n",
        "- ✅ Implemented TinyCNN architecture\n",
        "- ✅ Created training loop with metrics\n",
        "- ✅ Exported model to ONNX format\n",
        "- ✅ Verified export integrity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🧠 Träning & ONNX Export - Förstå vad som händer\n",
        "\n",
        "**Mål**: Förstå hur träning fungerar och experimentera med olika inställningar.\n",
        "\n",
        "I detta notebook kommer vi att:\n",
        "- Förstå vad FakeData är och varför vi använder det\n",
        "- Se hur dataset-pipeline → modell → loss/accuracy fungerar\n",
        "- Experimentera med olika hyperparametrar\n",
        "- Förstå varför vi exporterar till ONNX\n",
        "\n",
        "> **💡 Tips**: Kör cellerna i ordning och läs förklaringarna. Experimentera gärna med värdena!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🤔 Vad är FakeData och varför använder vi det?\n",
        "\n",
        "**FakeData** är syntetiska bilder som PyTorch genererar automatiskt. Det är perfekt för:\n",
        "- **Snabb prototyping** - ingen nedladdning av stora dataset\n",
        "- **Reproducerbarhet** - samma data varje gång\n",
        "- **Undervisning** - fokus på algoritmer, inte datahantering\n",
        "\n",
        "<details>\n",
        "<summary>🔍 Klicka för att se vad FakeData innehåller</summary>\n",
        "\n",
        "```python\n",
        "# FakeData genererar:\n",
        "# - Slumpmässiga RGB-bilder (64x64 pixlar)\n",
        "# - Slumpmässiga klasser (0, 1, 2, ...)\n",
        "# - Samma struktur som riktiga bilddataset\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Låt oss skapa en liten FakeData för att se vad den innehåller\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Skapa FakeData med 2 klasser\n",
        "fake_data = datasets.FakeData(size=10, num_classes=2, transform=None)\n",
        "\n",
        "# Visa första bilden\n",
        "image, label = fake_data[0]\n",
        "print(f\"Bildstorlek: {image.size}\")\n",
        "print(f\"Klass: {label}\")\n",
        "print(f\"Pixelvärden: {image.getextrema()}\")\n",
        "\n",
        "# Visa bilden\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.imshow(image)\n",
        "plt.title(f\"FakeData - Klass {label}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 Experimentera med Träning\n",
        "\n",
        "Nu ska vi träna en modell och se hur olika inställningar påverkar resultatet.\n",
        "\n",
        "**Hyperparametrar att experimentera med**:\n",
        "- `epochs` - antal genomgångar av datasetet\n",
        "- `batch_size` - antal bilder per träningssteg\n",
        "- `--no-pretrained` - börja från noll vs förtränade vikter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Experiment 1: Snabb träning (1 epoch, ingen pretrained)\n",
        "print(\"🧪 Experiment 1: Snabb träning\")\n",
        "!python -m piedge_edukit.train --fakedata --no-pretrained --epochs 1 --batch-size 128 --output-dir ./models_exp1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visa träningsresultat från Experiment 1\n",
        "import json\n",
        "import os\n",
        "\n",
        "if os.path.exists(\"./models_exp1/training_info.json\"):\n",
        "    with open(\"./models_exp1/training_info.json\", \"r\") as f:\n",
        "        info = json.load(f)\n",
        "    \n",
        "    print(\"📊 Träningsresultat (Experiment 1):\")\n",
        "    print(f\"Final accuracy: {info.get('final_accuracy', 'N/A'):.3f}\")\n",
        "    print(f\"Final loss: {info.get('final_loss', 'N/A'):.3f}\")\n",
        "    print(f\"Epochs: {info.get('epochs', 'N/A')}\")\n",
        "    print(f\"Batch size: {info.get('batch_size', 'N/A')}\")\n",
        "else:\n",
        "    print(\"❌ Träningsinfo saknas\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🤔 Reflektionsfrågor\n",
        "\n",
        "<details>\n",
        "<summary>💭 Vad händer med överfitting när du höjer epochs?</summary>\n",
        "\n",
        "**Svar**: Med fler epochs kan modellen lära sig träningsdata för bra och dåligt generalisera till nya data. Detta kallas överfitting.\n",
        "\n",
        "**Experiment**: Kör samma träning men med `--epochs 5` och jämför accuracy på tränings- vs valideringsdata.\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>💭 Varför exporterar vi till ONNX (för Pi/edge)?</summary>\n",
        "\n",
        "**Svar**: ONNX är ett standardformat som fungerar på många plattformar (CPU, GPU, mobil, edge). Det gör modellen portabel och optimerad för inference.\n",
        "\n",
        "**Fördelar**:\n",
        "- Snabbare inference än PyTorch\n",
        "- Mindre minnesanvändning\n",
        "- Fungerar på Raspberry Pi\n",
        "- Stöd för kvantisering (INT8)\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 Ditt eget experiment\n",
        "\n",
        "**Uppgift**: Träna en modell med andra inställningar och jämför resultaten.\n",
        "\n",
        "**Förslag**:\n",
        "- Öka epochs till 3-5\n",
        "- Ändra batch_size till 64 eller 256\n",
        "- Testa med och utan `--no-pretrained`\n",
        "\n",
        "**Kod att modifiera**:\n",
        "```python\n",
        "# Ändra dessa värden:\n",
        "EPOCHS = 3\n",
        "BATCH_SIZE = 64\n",
        "USE_PRETRAINED = False  # True för förtränade vikter\n",
        "\n",
        "!python -m piedge_edukit.train --fakedata --epochs {EPOCHS} --batch-size {BATCH_SIZE} --output-dir ./models_myexp\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Implementera ditt experiment här\n",
        "# Ändra värdena nedan och kör träningen\n",
        "\n",
        "EPOCHS = 3\n",
        "BATCH_SIZE = 64\n",
        "USE_PRETRAINED = False\n",
        "\n",
        "print(f\"🧪 Mitt experiment: epochs={EPOCHS}, batch_size={BATCH_SIZE}, pretrained={USE_PRETRAINED}\")\n",
        "\n",
        "# TODO: Kör träningen med dina inställningar\n",
        "# !python -m piedge_edukit.train --fakedata --epochs {EPOCHS} --batch-size {BATCH_SIZE} --output-dir ./models_myexp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎉 Sammanfattning\n",
        "\n",
        "Du har nu lärt dig:\n",
        "- Vad FakeData är och varför vi använder det\n",
        "- Hur träning fungerar med olika hyperparametrar\n",
        "- Varför ONNX-export är viktigt för edge deployment\n",
        "\n",
        "**Nästa steg**: Gå till `02_latency_benchmark.ipynb` för att förstå hur vi mäter modellens prestanda.\n",
        "\n",
        "**Viktiga begrepp**:\n",
        "- **Epochs**: Antal genomgångar av datasetet\n",
        "- **Batch size**: Antal bilder per träningssteg\n",
        "- **Pretrained weights**: Förtränade vikter från ImageNet\n",
        "- **ONNX**: Standardformat för edge deployment\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
