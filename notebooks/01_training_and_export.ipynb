{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap: Import helpers and create directories\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add repo root to Python path\n",
    "repo_root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "\n",
    "from utils.nb_helpers import run_module, run_script\n",
    "print(\"‚úÖ Notebook helpers loaded - ready for training!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Training & Export\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "* Understand the pieces of a PyTorch training loop (model ‚Üí loss ‚Üí optimizer ‚Üí data loader ‚Üí epochs).\n",
    "* Implement/inspect a tiny CNN and see how accuracy changes with hyper-parameters.\n",
    "* Export to ONNX and verify the file loads and produces outputs of the right shape/dtype.\n",
    "\n",
    "## You Should Be Able To...\n",
    "\n",
    "- Implement a basic CNN using PyTorch layers\n",
    "- Write a training loop with loss calculation and accuracy tracking\n",
    "- Export a trained model to ONNX format with proper input/output specifications\n",
    "- Explain why ONNX export is useful for edge deployment\n",
    "- Identify key hyperparameters that affect model performance\n",
    "\n",
    "---\n",
    "\n",
    "## Concepts\n",
    "\n",
    "**Training loop**: forward ‚Üí compute loss ‚Üí backward ‚Üí optimizer step ‚Üí repeat.\n",
    "\n",
    "**Evaluation mode**: `model.eval()` disables dropout/batchnorm updates for deterministic inference.\n",
    "\n",
    "**Export to ONNX**: we trace the model with a sample input and save `models/model.onnx`.\n",
    "\n",
    "**Preprocessing contract**: whatever normalization/resizing you used during training **must be used at inference** (outside the ONNX graph).\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "* Forgetting `model.eval()` before export (exporting training behavior).\n",
    "* Mismatch between training normalization and inference normalization (bad accuracy).\n",
    "* Exporting with the wrong input shape.\n",
    "\n",
    "## Success Criteria\n",
    "\n",
    "* ‚úÖ Training runs and prints accuracy\n",
    "* ‚úÖ `models/model.onnx` exists and can be loaded\n",
    "* ‚úÖ Checker says shapes/dtypes are valid\n",
    "\n",
    "---\n",
    "\n",
    "## Setup & Environment Check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa: E401\nimport os\nimport sys\nfrom pathlib import Path\n\n# Ensure repo root in path if opened from labs/\nif Path.cwd().name == \"labs\":\n    os.chdir(Path.cwd().parent)\n    print(\"‚Üí Working dir set to repo root:\", os.getcwd())\nif os.getcwd() not in sys.path:\n    sys.path.insert(0, os.getcwd())\n\n# Core deps\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport onnx\nfrom onnx import checker  # noqa: F401\nimport onnxruntime as ort  # noqa: F401\nimport matplotlib.pyplot as plt\nfrom torchvision.datasets import FakeData as TVFakeData\n\n# Project package\nfrom piedge_edukit.preprocess import FakeData as PEDFakeData\n\n# Hints & Solutions helper (pure Jupyter, no extra deps)\nfrom IPython.display import Markdown, display\n\ndef hints(*lines, solution: str | None = None, title=\"Need a nudge?\"):\n    \"\"\"Render progressive hints + optional collapsible solution.\"\"\"\n    md = [f\"### {title}\"]\n    for i, txt in enumerate(lines, start=1):\n        md.append(f\"<details><summary>Hint {i}</summary>\\n\\n{txt}\\n\\n</details>\")\n    if solution:\n        # keep code fenced as python for readability\n        md.append(\n            \"<details><summary><b>Show solution</b></summary>\\n\\n\"\n            f\"```python\\n{solution.strip()}\\n```\\n\"\n            \"</details>\"\n        )\n    display(Markdown(\"\\n\\n\".join(md)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment self-heal (Python 3.12 + editable install)\n",
    "import subprocess\n",
    "import importlib\n",
    "\n",
    "print(f\"Python: {sys.version.split()[0]} (need 3.12)\")\n",
    "\n",
    "try:\n",
    "    import piedge_edukit  # noqa: F401\n",
    "    print(\"‚úÖ PiEdge EduKit package OK\")\n",
    "except ModuleNotFoundError:\n",
    "    print(\"‚ÑπÔ∏è Installing package in editable mode ‚Ä¶\")\n",
    "    root = os.getcwd()\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", root])\n",
    "    importlib.invalidate_caches()\n",
    "    import piedge_edukit  # noqa: F401\n",
    "    print(\"‚úÖ Package installed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports are now in the first cell above\n",
    "print(\"‚úÖ All imports successful\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept: Convolutional Neural Networks\n",
    "\n",
    "CNNs are designed to process grid-like data (images) by:\n",
    "- **Convolutional layers**: Learn spatial patterns (edges, textures, shapes)\n",
    "- **Pooling layers**: Reduce spatial dimensions while preserving important features\n",
    "- **Fully connected layers**: Make final classification decisions\n",
    "\n",
    "For 64√ó64 RGB images, a typical architecture flows: `[3,64,64] ‚Üí Conv ‚Üí ReLU ‚Üí Pool ‚Üí Conv ‚Üí ReLU ‚Üí Pool ‚Üí Flatten ‚Üí Linear ‚Üí Linear ‚Üí [num_classes]`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A: Implement a Simple CNN\n\nYour task is to implement a `TinyCNN` class that can classify 64√ó64 RGB images into 2 classes.\n\n### TODO A1 ‚Äî Implement `TinyCNN`\n**Goal:** Build a minimal Conv ‚Üí ReLU ‚Üí MaxPool stack ending in a linear head.\n\n<details><summary>Hint 1</summary>\nStart with 3√ó3 conv, stride=1, padding=1. Use MaxPool 2√ó2 to downsample.\n</details>\n\n<details><summary>Hint 2</summary>\nTwo conv blocks are enough for FakeData. Flatten before the linear layer.\n</details>\n\n<details><summary>Hint 3</summary>\n`forward(x)` should return logits (no softmax).\n</details>\n\n<details><summary>Solution</summary>\n\n```python\nimport torch.nn as nn\n\nclass TinyCNN(nn.Module):\n    def __init__(self, num_classes=10):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Conv2d(3, 16, 3, padding=1), nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(),\n            nn.MaxPool2d(2),\n        )\n        self.head = nn.Linear(32*8*8, num_classes)\n\n    def forward(self, x):\n        x = self.net(x)\n        x = x.view(x.size(0), -1)\n        return self.head(x)\n```\n\n</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO A1: implement TinyCNN here (or edit if already stubbed)\n",
    "\n",
    "# Create model instance\n",
    "model = TinyCNN(num_classes=2)\n",
    "print(f\"Model created with {sum(p.numel() for p in model.parameters())} parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST: model should accept [1,3,64,64] and output [1,2]\n",
    "# (torch already imported in first cell)\n",
    "x = torch.randn(1,3,64,64)\n",
    "y = model(x)\n",
    "assert y.shape == (1,2), f\"Expected (1,2), got {tuple(y.shape)}\"\n",
    "print(\"‚úÖ Shape test passed\")\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {y.shape}\")\n",
    "print(f\"Output range: [{y.min().item():.3f}, {y.max().item():.3f}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept: Training Loop Components\n",
    "\n",
    "A typical training loop includes:\n",
    "1. **Forward pass**: Compute predictions\n",
    "2. **Loss calculation**: Compare predictions to ground truth\n",
    "3. **Backward pass**: Compute gradients\n",
    "4. **Optimizer step**: Update model parameters\n",
    "5. **Metrics tracking**: Monitor loss and accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B: Write the Training Step\n\nImplement a `train_one_epoch` function that trains the model for one epoch and returns loss and accuracy metrics.\n\n### TODO B1 ‚Äî Implement one training step\n**Goal:** zero_grad ‚Üí forward ‚Üí compute loss ‚Üí backward ‚Üí step\n\n<details><summary>Hint 1</summary>\n`optimizer.zero_grad()` must be called before `loss.backward()`.\n</details>\n\n<details><summary>Hint 2</summary>\nUse `model.train()` during training.\n</details>\n\n<details><summary>Solution</summary>\n\n```python\ndef train_step(model, batch, optimizer, criterion):\n    model.train()\n    x, y = batch\n    optimizer.zero_grad()\n    logits = model(x)\n    loss = criterion(logits, y)\n    loss.backward()\n    optimizer.step()\n    return float(loss.detach().cpu())\n```\n\n</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO B1: implement train_step(...)\n",
    "\n",
    "# Test the function signature\n",
    "print(\"‚úÖ Function signature looks correct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test data and test the training function\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Create fake data loader\nfake_data = FakeData(num_samples=100, image_size=64, num_classes=2)\ntrain_loader = DataLoader(fake_data, batch_size=16, shuffle=True)\n\n# Create optimizer\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Test training function\nmetrics = train_one_epoch(model, train_loader, optimizer, device)\nassert \"loss\" in metrics and \"acc\" in metrics\nprint(\"‚úÖ Training loop smoke test passed\")\nprint(f\"Loss: {metrics['loss']:.4f}, Accuracy: {metrics['acc']:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept: ONNX Export\n",
    "\n",
    "ONNX (Open Neural Network Exchange) is a format that allows models to run on different platforms:\n",
    "- **Cross-platform**: Same model runs on CPU, GPU, mobile, edge devices\n",
    "- **Optimized inference**: ONNX Runtime provides optimized execution\n",
    "- **Language agnostic**: Models can be used from Python, C++, C#, JavaScript, etc.\n",
    "\n",
    "Key requirements for export:\n",
    "- Model must be in evaluation mode (`model.eval()`)\n",
    "- Provide a dummy input with correct shape\n",
    "- Specify input/output names for clarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task C: Export to ONNX\n",
    "\n",
    "Export your trained model to ONNX format for edge deployment.\n",
    "\n",
    "### TODO C1 ‚Äî Export to ONNX with dynamic axes\n",
    "**Goal:** Put model in `eval()`, feed a dummy input, export to `models/model.onnx`.\n",
    "\n",
    "<details><summary>Hint 1</summary>\n",
    "Use `torch.onnx.export(model, dummy, \"models/model.onnx\", opset_version=17, dynamic_axes=...)`.\n",
    "</details>\n",
    "\n",
    "<details><summary>Hint 2</summary>\n",
    "`dynamic_axes={\"input\": {0: \"batch\"}, \"output\": {0: \"batch\"}}`.\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "import torch, os\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "model.eval()\n",
    "dummy = torch.randn(1, 3, 32, 32)\n",
    "torch.onnx.export(\n",
    "    model, dummy, \"models/model.onnx\",\n",
    "    input_names=[\"input\"], output_names=[\"output\"],\n",
    "    dynamic_axes={\"input\": {0: \"batch\"}, \"output\": {0: \"batch\"}},\n",
    "    opset_version=17\n",
    ")\n",
    "print(\"[OK] Exported to models/model.onnx\")\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO C1: export ONNX here\n",
    "\n",
    "print(\"‚úÖ ONNX export completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ONNX export\n",
    "# (onnx and os already imported in first cell)\n",
    "assert os.path.exists(\"./models/model.onnx\"), \"ONNX file missing\"\n",
    "m = onnx.load(\"./models/model.onnx\")\n",
    "onnx.checker.check_model(m)\n",
    "print(\"‚úÖ ONNX export verified\")\n",
    "\n",
    "# Show model info\n",
    "file_size = os.path.getsize(\"./models/model.onnx\") / (1024*1024)\n",
    "print(f\"Model size: {file_size:.2f} MB\")\n",
    "print(f\"Input shape: {[d.dim_value for d in m.graph.input[0].type.tensor_type.shape.dim]}\")\n",
    "print(f\"Output shape: {[d.dim_value for d in m.graph.output[0].type.tensor_type.shape.dim]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Questions\n",
    "\n",
    "Please answer these questions in 2-3 sentences each:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. What two hyperparameters most affected your validation accuracy? Why?**\n",
    "\n",
    "*Your answer here (2-3 sentences):*\n",
    "\n",
    "---\n",
    "\n",
    "**2. Why is exporting to ONNX useful for edge deployment?**\n",
    "\n",
    "*Your answer here (2-3 sentences):*\n",
    "\n",
    "---\n",
    "\n",
    "**3. What would happen if you forgot to call `model.eval()` before ONNX export?**\n",
    "\n",
    "*Your answer here (2-3 sentences):*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Great work! You've implemented a CNN, trained it, and exported it to ONNX format.\n",
    "\n",
    "**Next**: Open `02_latency_benchmark.ipynb` to learn about performance measurement and optimization.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "- ‚úÖ Implemented TinyCNN architecture\n",
    "- ‚úÖ Created training loop with metrics\n",
    "- ‚úÖ Exported model to ONNX format\n",
    "- ‚úÖ Verified export integrity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Training & ONNX Export - Understand what's happening\n\n**Goal**: Understand how training works and experiment with different settings.\n\nIn this notebook we will:\n- Understand what FakeData is and why we use it\n- See how dataset-pipeline ‚Üí model ‚Üí loss/accuracy works\n- Experiment with different hyperparameters\n- Understand why we export to ONNX\n\n> **üí° Tip**: Run the cells in order and read the explanations. Feel free to experiment with the values!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§î What is FakeData and why do we use it?\n\n**FakeData** are synthetic images that PyTorch generates automatically. It's perfect for:\n- **Quick prototyping** - no downloading of large datasets\n- **Reproducibility** - same data every time\n- **Teaching** - focus on algorithms, not data management\n\n<details>\n<summary>üîç Click to see what FakeData contains</summary>\n\n```python\n# FakeData generates:\n# - Random RGB images (64x64 pixels)\n# - Random classes (0, 1, 2, ...)\n# - Same structure as real image datasets\n```\n\n</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a small FakeData to see what it contains\nimport torch\nfrom torchvision import datasets\nimport matplotlib.pyplot as plt\n\n# Create FakeData with 2 classes\nfake_data = datasets.FakeData(size=10, num_classes=2, transform=None)\n\n# Show first image\nimage, label = fake_data[0]\nprint(f\"Image size: {image.size}\")\nprint(f\"Class: {label}\")\nprint(f\"Pixel values: {image.getextrema()}\")\n\n# Show the image\nplt.figure(figsize=(6, 4))\nplt.imshow(image)\nplt.title(f\"FakeData - Class {label}\")\nplt.axis('off')\nplt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Experiment with Training\n",
    "\n",
    "Now we'll train a model and see how different settings affect the results.\n",
    "\n",
    "**Hyperparameters to experiment with**:\n",
    "- `epochs` - number of passes through the dataset\n",
    "- `batch_size` - number of images per training step\n",
    "- `--no-pretrained` - start from scratch vs pretrained weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1: Quick training (1 epoch, no pretrained)\n",
    "print(\"üß™ Experiment 1: Quick training\")\n",
    "!python -m piedge_edukit.train --fakedata --no-pretrained --epochs 1 --batch-size 128 --output-dir ./models_exp1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show training results from Experiment 1\n",
    "import json\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"./models_exp1/training_info.json\"):\n",
    "    with open(\"./models_exp1/training_info.json\", \"r\") as f:\n",
    "        info = json.load(f)\n",
    "    \n",
    "    print(\"üìä Training results (Experiment 1):\")\n",
    "    print(f\"Final accuracy: {info.get('final_accuracy', 'N/A'):.3f}\")\n",
    "    print(f\"Final loss: {info.get('final_loss', 'N/A'):.3f}\")\n",
    "    print(f\"Epochs: {info.get('epochs', 'N/A')}\")\n",
    "    print(f\"Batch size: {info.get('batch_size', 'N/A')}\")\n",
    "else:\n",
    "    print(\"‚ùå Training info missing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§î Reflection Questions\n",
    "\n",
    "<details>\n",
    "<summary>üí≠ What happens with overfitting when you increase epochs?</summary>\n",
    "\n",
    "**Answer**: With more epochs, the model can learn the training data too well and generalize poorly to new data. This is called overfitting.\n",
    "\n",
    "**Experiment**: Run the same training but with `--epochs 5` and compare accuracy on training vs validation data.\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>üí≠ Why do we export to ONNX (for Pi/edge)?</summary>\n",
    "\n",
    "**Answer**: ONNX is a standard format that works on many platforms (CPU, GPU, mobile, edge). It makes the model portable and optimized for inference.\n",
    "\n",
    "**Benefits**:\n",
    "- Faster inference than PyTorch\n",
    "- Less memory usage\n",
    "- Works on Raspberry Pi\n",
    "- Support for quantization (INT8)\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Your own experiment\n",
    "\n",
    "**Task**: Train a model with different settings and compare the results.\n",
    "\n",
    "**Suggestions**:\n",
    "- Increase epochs to 3-5\n",
    "- Change batch_size to 64 or 256\n",
    "- Test with and without `--no-pretrained`\n",
    "\n",
    "**Code to modify**:\n",
    "```python\n",
    "# Change these values:\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 64\n",
    "USE_PRETRAINED = False  # True for pretrained weights\n",
    "\n",
    "!python -m piedge_edukit.train --fakedata --epochs {EPOCHS} --batch-size {BATCH_SIZE} --output-dir ./models_myexp\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement your experiment here\n",
    "# Change the values below and run the training\n",
    "\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 64\n",
    "USE_PRETRAINED = False\n",
    "\n",
    "print(f\"üß™ My experiment: epochs={EPOCHS}, batch_size={BATCH_SIZE}, pretrained={USE_PRETRAINED}\")\n",
    "\n",
    "# TODO: Run the training with your settings\n",
    "# !python -m piedge_edukit.train --fakedata --epochs {EPOCHS} --batch-size {BATCH_SIZE} --output-dir ./models_myexp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Summary\n\nYou have now learned:\n- What FakeData is and why we use it\n- How training works with different hyperparameters\n- Why ONNX export is important for edge deployment\n\n**Next step**: Go to `02_latency_benchmark.ipynb` to understand how we measure model performance.\n\n**Key concepts**:\n- **Epochs**: Number of passes through the dataset\n- **Batch size**: Number of images per training step\n- **Pretrained weights**: Pre-trained weights from ImageNet\n- **ONNX**: Standard format for edge deployment\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}