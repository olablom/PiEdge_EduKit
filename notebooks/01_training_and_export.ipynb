{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 - Training & Export\n",
        "\n",
        "## Learning Goals\n",
        "\n",
        "* Understand the pieces of a PyTorch training loop (model ‚Üí loss ‚Üí optimizer ‚Üí data loader ‚Üí epochs).\n",
        "* Implement/inspect a tiny CNN and see how accuracy changes with hyper-parameters.\n",
        "* Export to ONNX and verify the file loads and produces outputs of the right shape/dtype.\n",
        "\n",
        "## You Should Be Able To...\n",
        "\n",
        "- Implement a basic CNN using PyTorch layers\n",
        "- Write a training loop with loss calculation and accuracy tracking\n",
        "- Export a trained model to ONNX format with proper input/output specifications\n",
        "- Explain why ONNX export is useful for edge deployment\n",
        "- Identify key hyperparameters that affect model performance\n",
        "\n",
        "---\n",
        "\n",
        "## Concepts\n",
        "\n",
        "**Training loop**: forward ‚Üí compute loss ‚Üí backward ‚Üí optimizer step ‚Üí repeat.\n",
        "\n",
        "**Evaluation mode**: `model.eval()` disables dropout/batchnorm updates for deterministic inference.\n",
        "\n",
        "**Export to ONNX**: we trace the model with a sample input and save `models/model.onnx`.\n",
        "\n",
        "**Preprocessing contract**: whatever normalization/resizing you used during training **must be used at inference** (outside the ONNX graph).\n",
        "\n",
        "## Common Pitfalls\n",
        "\n",
        "* Forgetting `model.eval()` before export (exporting training behavior).\n",
        "* Mismatch between training normalization and inference normalization (bad accuracy).\n",
        "* Exporting with the wrong input shape.\n",
        "\n",
        "## Success Criteria\n",
        "\n",
        "* ‚úÖ Training runs and prints accuracy\n",
        "* ‚úÖ `models/model.onnx` exists and can be loaded\n",
        "* ‚úÖ Checker says shapes/dtypes are valid\n",
        "\n",
        "---\n",
        "\n",
        "## Setup & Environment Check\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ruff: noqa: E401\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Ensure repo root in path if opened from labs/\n",
        "if Path.cwd().name == \"labs\":\n",
        "    os.chdir(Path.cwd().parent)\n",
        "    print(\"‚Üí Working dir set to repo root:\", os.getcwd())\n",
        "if os.getcwd() not in sys.path:\n",
        "    sys.path.insert(0, os.getcwd())\n",
        "\n",
        "# Core deps\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import onnx\n",
        "from onnx import checker  # noqa: F401\n",
        "import onnxruntime as ort  # noqa: F401\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.datasets import FakeData as TVFakeData\n",
        "\n",
        "# Project package\n",
        "from piedge_edukit.preprocess import FakeData as PEDFakeData\n",
        "\n",
        "# Hints & Solutions helper (pure Jupyter, no extra deps)\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "def hints(*lines, solution: str | None = None, title=\"Need a nudge?\"):\n",
        "    \"\"\"Render progressive hints + optional collapsible solution.\"\"\"\n",
        "    md = [f\"### {title}\"]\n",
        "    for i, txt in enumerate(lines, start=1):\n",
        "        md.append(f\"<details><summary>Hint {i}</summary>\\n\\n{txt}\\n\\n</details>\")\n",
        "    if solution:\n",
        "        # keep code fenced as python for readability\n",
        "        md.append(\n",
        "            \"<details><summary><b>Show solution</b></summary>\\n\\n\"\n",
        "            f\"```python\\n{solution.strip()}\\n```\\n\"\n",
        "            \"</details>\"\n",
        "        )\n",
        "    display(Markdown(\"\\n\\n\".join(md)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Environment self-heal (Python 3.12 + editable install)\n",
        "import subprocess\n",
        "import importlib\n",
        "\n",
        "print(f\"Python: {sys.version.split()[0]} (need 3.12)\")\n",
        "\n",
        "try:\n",
        "    import piedge_edukit  # noqa: F401\n",
        "    print(\"‚úÖ PiEdge EduKit package OK\")\n",
        "except ModuleNotFoundError:\n",
        "    print(\"‚ÑπÔ∏è Installing package in editable mode ‚Ä¶\")\n",
        "    root = os.getcwd()\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", root])\n",
        "    importlib.invalidate_caches()\n",
        "    import piedge_edukit  # noqa: F401\n",
        "    print(\"‚úÖ Package installed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# All imports are now in the first cell above\n",
        "print(\"‚úÖ All imports successful\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Concept: Convolutional Neural Networks\n",
        "\n",
        "CNNs are designed to process grid-like data (images) by:\n",
        "- **Convolutional layers**: Learn spatial patterns (edges, textures, shapes)\n",
        "- **Pooling layers**: Reduce spatial dimensions while preserving important features\n",
        "- **Fully connected layers**: Make final classification decisions\n",
        "\n",
        "For 64√ó64 RGB images, a typical architecture flows: `[3,64,64] ‚Üí Conv ‚Üí ReLU ‚Üí Pool ‚Üí Conv ‚Üí ReLU ‚Üí Pool ‚Üí Flatten ‚Üí Linear ‚Üí Linear ‚Üí [num_classes]`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task A: Implement a Simple CNN\n",
        "\n",
        "Your task is to implement a `TinyCNN` class that can classify 64√ó64 RGB images into 2 classes.\n",
        "\n",
        "### TODO A1 ‚Äî Implement `TinyCNN`\n",
        "**Goal:** Build a minimal Conv ‚Üí ReLU ‚Üí MaxPool stack ending in a linear head.\n",
        "\n",
        "<details><summary>Hint 1</summary>\n",
        "Start with 3√ó3 conv, stride=1, padding=1. Use MaxPool 2√ó2 to downsample.\n",
        "</details>\n",
        "\n",
        "<details><summary>Hint 2</summary>\n",
        "Two conv blocks are enough for FakeData. Flatten before the linear layer.\n",
        "</details>\n",
        "\n",
        "<details><summary>Hint 3</summary>\n",
        "`forward(x)` should return logits (no softmax).\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "import torch.nn as nn\n",
        "\n",
        "class TinyCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.head = nn.Linear(32*8*8, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.head(x)\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO A1: implement TinyCNN here (or edit if already stubbed)\n",
        "\n",
        "# Create model instance\n",
        "model = TinyCNN(num_classes=2)\n",
        "print(f\"Model created with {sum(p.numel() for p in model.parameters())} parameters\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TEST: model should accept [1,3,64,64] and output [1,2]\n",
        "# (torch already imported in first cell)\n",
        "x = torch.randn(1,3,64,64)\n",
        "y = model(x)\n",
        "assert y.shape == (1,2), f\"Expected (1,2), got {tuple(y.shape)}\"\n",
        "print(\"‚úÖ Shape test passed\")\n",
        "print(f\"Input shape: {x.shape}\")\n",
        "print(f\"Output shape: {y.shape}\")\n",
        "print(f\"Output range: [{y.min().item():.3f}, {y.max().item():.3f}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Concept: Training Loop Components\n",
        "\n",
        "A typical training loop includes:\n",
        "1. **Forward pass**: Compute predictions\n",
        "2. **Loss calculation**: Compare predictions to ground truth\n",
        "3. **Backward pass**: Compute gradients\n",
        "4. **Optimizer step**: Update model parameters\n",
        "5. **Metrics tracking**: Monitor loss and accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task B: Write the Training Step\n",
        "\n",
        "Implement a `train_one_epoch` function that trains the model for one epoch and returns loss and accuracy metrics.\n",
        "\n",
        "### TODO B1 ‚Äî Implement one training step\n",
        "**Goal:** zero_grad ‚Üí forward ‚Üí compute loss ‚Üí backward ‚Üí step\n",
        "\n",
        "<details><summary>Hint 1</summary>\n",
        "`optimizer.zero_grad()` m√•ste kallas f√∂re `loss.backward()`.\n",
        "</details>\n",
        "\n",
        "<details><summary>Hint 2</summary>\n",
        "Anv√§nd `model.train()` under tr√§ning.\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def train_step(model, batch, optimizer, criterion):\n",
        "    model.train()\n",
        "    x, y = batch\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(x)\n",
        "    loss = criterion(logits, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss.detach().cpu())\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO B1: implement train_step(...)\n",
        "\n",
        "# Test the function signature\n",
        "print(\"‚úÖ Function signature looks correct\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create test data and test the training function\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Create fake data loader\n",
        "fake_data = FakeData(num_samples=100, image_size=64, num_classes=2)\n",
        "train_loader = DataLoader(fake_data, batch_size=16, shuffle=True)\n",
        "\n",
        "# Create optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Test training function\n",
        "metrics = train_one_epoch(model, train_loader, optimizer, device)\n",
        "assert \"loss\" in metrics and \"acc\" in metrics\n",
        "print(\"‚úÖ Training loop smoke test passed\")\n",
        "print(f\"Loss: {metrics['loss']:.4f}, Accuracy: {metrics['acc']:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Concept: ONNX Export\n",
        "\n",
        "ONNX (Open Neural Network Exchange) is a format that allows models to run on different platforms:\n",
        "- **Cross-platform**: Same model runs on CPU, GPU, mobile, edge devices\n",
        "- **Optimized inference**: ONNX Runtime provides optimized execution\n",
        "- **Language agnostic**: Models can be used from Python, C++, C#, JavaScript, etc.\n",
        "\n",
        "Key requirements for export:\n",
        "- Model must be in evaluation mode (`model.eval()`)\n",
        "- Provide a dummy input with correct shape\n",
        "- Specify input/output names for clarity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task C: Export to ONNX\n",
        "\n",
        "Export your trained model to ONNX format for edge deployment.\n",
        "\n",
        "### TODO C1 ‚Äî Export to ONNX with dynamic axes\n",
        "**Goal:** Put model in `eval()`, feed a dummy input, export to `models/model.onnx`.\n",
        "\n",
        "<details><summary>Hint 1</summary>\n",
        "Use `torch.onnx.export(model, dummy, \"models/model.onnx\", opset_version=17, dynamic_axes=...)`.\n",
        "</details>\n",
        "\n",
        "<details><summary>Hint 2</summary>\n",
        "`dynamic_axes={\"input\": {0: \"batch\"}, \"output\": {0: \"batch\"}}`.\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "import torch, os\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "model.eval()\n",
        "dummy = torch.randn(1, 3, 32, 32)\n",
        "torch.onnx.export(\n",
        "    model, dummy, \"models/model.onnx\",\n",
        "    input_names=[\"input\"], output_names=[\"output\"],\n",
        "    dynamic_axes={\"input\": {0: \"batch\"}, \"output\": {0: \"batch\"}},\n",
        "    opset_version=17\n",
        ")\n",
        "print(\"[OK] Exported to models/model.onnx\")\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO C1: export ONNX here\n",
        "\n",
        "print(\"‚úÖ ONNX export completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test ONNX export\n",
        "# (onnx and os already imported in first cell)\n",
        "assert os.path.exists(\"./models/model.onnx\"), \"ONNX file missing\"\n",
        "m = onnx.load(\"./models/model.onnx\")\n",
        "onnx.checker.check_model(m)\n",
        "print(\"‚úÖ ONNX export verified\")\n",
        "\n",
        "# Show model info\n",
        "file_size = os.path.getsize(\"./models/model.onnx\") / (1024*1024)\n",
        "print(f\"Model size: {file_size:.2f} MB\")\n",
        "print(f\"Input shape: {[d.dim_value for d in m.graph.input[0].type.tensor_type.shape.dim]}\")\n",
        "print(f\"Output shape: {[d.dim_value for d in m.graph.output[0].type.tensor_type.shape.dim]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection Questions\n",
        "\n",
        "Please answer these questions in 2-3 sentences each:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**1. What two hyperparameters most affected your validation accuracy? Why?**\n",
        "\n",
        "*Your answer here (2-3 sentences):*\n",
        "\n",
        "---\n",
        "\n",
        "**2. Why is exporting to ONNX useful for edge deployment?**\n",
        "\n",
        "*Your answer here (2-3 sentences):*\n",
        "\n",
        "---\n",
        "\n",
        "**3. What would happen if you forgot to call `model.eval()` before ONNX export?**\n",
        "\n",
        "*Your answer here (2-3 sentences):*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "Great work! You've implemented a CNN, trained it, and exported it to ONNX format.\n",
        "\n",
        "**Next**: Open `02_latency_benchmark.ipynb` to learn about performance measurement and optimization.\n",
        "\n",
        "---\n",
        "\n",
        "### Summary\n",
        "- ‚úÖ Implemented TinyCNN architecture\n",
        "- ‚úÖ Created training loop with metrics\n",
        "- ‚úÖ Exported model to ONNX format\n",
        "- ‚úÖ Verified export integrity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß† Tr√§ning & ONNX Export - F√∂rst√• vad som h√§nder\n",
        "\n",
        "**M√•l**: F√∂rst√• hur tr√§ning fungerar och experimentera med olika inst√§llningar.\n",
        "\n",
        "I detta notebook kommer vi att:\n",
        "- F√∂rst√• vad FakeData √§r och varf√∂r vi anv√§nder det\n",
        "- Se hur dataset-pipeline ‚Üí modell ‚Üí loss/accuracy fungerar\n",
        "- Experimentera med olika hyperparametrar\n",
        "- F√∂rst√• varf√∂r vi exporterar till ONNX\n",
        "\n",
        "> **üí° Tips**: K√∂r cellerna i ordning och l√§s f√∂rklaringarna. Experimentera g√§rna med v√§rdena!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§î Vad √§r FakeData och varf√∂r anv√§nder vi det?\n",
        "\n",
        "**FakeData** √§r syntetiska bilder som PyTorch genererar automatiskt. Det √§r perfekt f√∂r:\n",
        "- **Snabb prototyping** - ingen nedladdning av stora dataset\n",
        "- **Reproducerbarhet** - samma data varje g√•ng\n",
        "- **Undervisning** - fokus p√• algoritmer, inte datahantering\n",
        "\n",
        "<details>\n",
        "<summary>üîç Klicka f√∂r att se vad FakeData inneh√•ller</summary>\n",
        "\n",
        "```python\n",
        "# FakeData genererar:\n",
        "# - Slumpm√§ssiga RGB-bilder (64x64 pixlar)\n",
        "# - Slumpm√§ssiga klasser (0, 1, 2, ...)\n",
        "# - Samma struktur som riktiga bilddataset\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# L√•t oss skapa en liten FakeData f√∂r att se vad den inneh√•ller\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Skapa FakeData med 2 klasser\n",
        "fake_data = datasets.FakeData(size=10, num_classes=2, transform=None)\n",
        "\n",
        "# Visa f√∂rsta bilden\n",
        "image, label = fake_data[0]\n",
        "print(f\"Bildstorlek: {image.size}\")\n",
        "print(f\"Klass: {label}\")\n",
        "print(f\"Pixelv√§rden: {image.getextrema()}\")\n",
        "\n",
        "# Visa bilden\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.imshow(image)\n",
        "plt.title(f\"FakeData - Klass {label}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Experimentera med Tr√§ning\n",
        "\n",
        "Nu ska vi tr√§na en modell och se hur olika inst√§llningar p√•verkar resultatet.\n",
        "\n",
        "**Hyperparametrar att experimentera med**:\n",
        "- `epochs` - antal genomg√•ngar av datasetet\n",
        "- `batch_size` - antal bilder per tr√§ningssteg\n",
        "- `--no-pretrained` - b√∂rja fr√•n noll vs f√∂rtr√§nade vikter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Experiment 1: Snabb tr√§ning (1 epoch, ingen pretrained)\n",
        "print(\"üß™ Experiment 1: Snabb tr√§ning\")\n",
        "!python -m piedge_edukit.train --fakedata --no-pretrained --epochs 1 --batch-size 128 --output-dir ./models_exp1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visa tr√§ningsresultat fr√•n Experiment 1\n",
        "import json\n",
        "import os\n",
        "\n",
        "if os.path.exists(\"./models_exp1/training_info.json\"):\n",
        "    with open(\"./models_exp1/training_info.json\", \"r\") as f:\n",
        "        info = json.load(f)\n",
        "    \n",
        "    print(\"üìä Tr√§ningsresultat (Experiment 1):\")\n",
        "    print(f\"Final accuracy: {info.get('final_accuracy', 'N/A'):.3f}\")\n",
        "    print(f\"Final loss: {info.get('final_loss', 'N/A'):.3f}\")\n",
        "    print(f\"Epochs: {info.get('epochs', 'N/A')}\")\n",
        "    print(f\"Batch size: {info.get('batch_size', 'N/A')}\")\n",
        "else:\n",
        "    print(\"‚ùå Tr√§ningsinfo saknas\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§î Reflektionsfr√•gor\n",
        "\n",
        "<details>\n",
        "<summary>üí≠ Vad h√§nder med √∂verfitting n√§r du h√∂jer epochs?</summary>\n",
        "\n",
        "**Svar**: Med fler epochs kan modellen l√§ra sig tr√§ningsdata f√∂r bra och d√•ligt generalisera till nya data. Detta kallas √∂verfitting.\n",
        "\n",
        "**Experiment**: K√∂r samma tr√§ning men med `--epochs 5` och j√§mf√∂r accuracy p√• tr√§nings- vs valideringsdata.\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>üí≠ Varf√∂r exporterar vi till ONNX (f√∂r Pi/edge)?</summary>\n",
        "\n",
        "**Svar**: ONNX √§r ett standardformat som fungerar p√• m√•nga plattformar (CPU, GPU, mobil, edge). Det g√∂r modellen portabel och optimerad f√∂r inference.\n",
        "\n",
        "**F√∂rdelar**:\n",
        "- Snabbare inference √§n PyTorch\n",
        "- Mindre minnesanv√§ndning\n",
        "- Fungerar p√• Raspberry Pi\n",
        "- St√∂d f√∂r kvantisering (INT8)\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Ditt eget experiment\n",
        "\n",
        "**Uppgift**: Tr√§na en modell med andra inst√§llningar och j√§mf√∂r resultaten.\n",
        "\n",
        "**F√∂rslag**:\n",
        "- √ñka epochs till 3-5\n",
        "- √Ñndra batch_size till 64 eller 256\n",
        "- Testa med och utan `--no-pretrained`\n",
        "\n",
        "**Kod att modifiera**:\n",
        "```python\n",
        "# √Ñndra dessa v√§rden:\n",
        "EPOCHS = 3\n",
        "BATCH_SIZE = 64\n",
        "USE_PRETRAINED = False  # True f√∂r f√∂rtr√§nade vikter\n",
        "\n",
        "!python -m piedge_edukit.train --fakedata --epochs {EPOCHS} --batch-size {BATCH_SIZE} --output-dir ./models_myexp\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Implementera ditt experiment h√§r\n",
        "# √Ñndra v√§rdena nedan och k√∂r tr√§ningen\n",
        "\n",
        "EPOCHS = 3\n",
        "BATCH_SIZE = 64\n",
        "USE_PRETRAINED = False\n",
        "\n",
        "print(f\"üß™ Mitt experiment: epochs={EPOCHS}, batch_size={BATCH_SIZE}, pretrained={USE_PRETRAINED}\")\n",
        "\n",
        "# TODO: K√∂r tr√§ningen med dina inst√§llningar\n",
        "# !python -m piedge_edukit.train --fakedata --epochs {EPOCHS} --batch-size {BATCH_SIZE} --output-dir ./models_myexp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ Sammanfattning\n",
        "\n",
        "Du har nu l√§rt dig:\n",
        "- Vad FakeData √§r och varf√∂r vi anv√§nder det\n",
        "- Hur tr√§ning fungerar med olika hyperparametrar\n",
        "- Varf√∂r ONNX-export √§r viktigt f√∂r edge deployment\n",
        "\n",
        "**N√§sta steg**: G√• till `02_latency_benchmark.ipynb` f√∂r att f√∂rst√• hur vi m√§ter modellens prestanda.\n",
        "\n",
        "**Viktiga begrepp**:\n",
        "- **Epochs**: Antal genomg√•ngar av datasetet\n",
        "- **Batch size**: Antal bilder per tr√§ningssteg\n",
        "- **Pretrained weights**: F√∂rtr√§nade vikter fr√•n ImageNet\n",
        "- **ONNX**: Standardformat f√∂r edge deployment\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
