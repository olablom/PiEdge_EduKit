{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß† Tr√§ning & ONNX Export - F√∂rst√• vad som h√§nder\n",
        "\n",
        "**M√•l**: F√∂rst√• hur tr√§ning fungerar och experimentera med olika inst√§llningar.\n",
        "\n",
        "I detta notebook kommer vi att:\n",
        "- F√∂rst√• vad FakeData √§r och varf√∂r vi anv√§nder det\n",
        "- Se hur dataset-pipeline ‚Üí modell ‚Üí loss/accuracy fungerar\n",
        "- Experimentera med olika hyperparametrar\n",
        "- F√∂rst√• varf√∂r vi exporterar till ONNX\n",
        "\n",
        "> **üí° Tips**: K√∂r cellerna i ordning och l√§s f√∂rklaringarna. Experimentera g√§rna med v√§rdena!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§î Vad √§r FakeData och varf√∂r anv√§nder vi det?\n",
        "\n",
        "**FakeData** √§r syntetiska bilder som PyTorch genererar automatiskt. Det √§r perfekt f√∂r:\n",
        "- **Snabb prototyping** - ingen nedladdning av stora dataset\n",
        "- **Reproducerbarhet** - samma data varje g√•ng\n",
        "- **Undervisning** - fokus p√• algoritmer, inte datahantering\n",
        "\n",
        "<details>\n",
        "<summary>üîç Klicka f√∂r att se vad FakeData inneh√•ller</summary>\n",
        "\n",
        "```python\n",
        "# FakeData genererar:\n",
        "# - Slumpm√§ssiga RGB-bilder (64x64 pixlar)\n",
        "# - Slumpm√§ssiga klasser (0, 1, 2, ...)\n",
        "# - Samma struktur som riktiga bilddataset\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# L√•t oss skapa en liten FakeData f√∂r att se vad den inneh√•ller\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Skapa FakeData med 2 klasser\n",
        "fake_data = datasets.FakeData(size=10, num_classes=2, transform=None)\n",
        "\n",
        "# Visa f√∂rsta bilden\n",
        "image, label = fake_data[0]\n",
        "print(f\"Bildstorlek: {image.size}\")\n",
        "print(f\"Klass: {label}\")\n",
        "print(f\"Pixelv√§rden: {image.getextrema()}\")\n",
        "\n",
        "# Visa bilden\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.imshow(image)\n",
        "plt.title(f\"FakeData - Klass {label}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Experimentera med Tr√§ning\n",
        "\n",
        "Nu ska vi tr√§na en modell och se hur olika inst√§llningar p√•verkar resultatet.\n",
        "\n",
        "**Hyperparametrar att experimentera med**:\n",
        "- `epochs` - antal genomg√•ngar av datasetet\n",
        "- `batch_size` - antal bilder per tr√§ningssteg\n",
        "- `--no-pretrained` - b√∂rja fr√•n noll vs f√∂rtr√§nade vikter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Experiment 1: Snabb tr√§ning (1 epoch, ingen pretrained)\n",
        "print(\"üß™ Experiment 1: Snabb tr√§ning\")\n",
        "!python -m piedge_edukit.train --fakedata --no-pretrained --epochs 1 --batch-size 128 --output-dir ./models_exp1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visa tr√§ningsresultat fr√•n Experiment 1\n",
        "import json\n",
        "import os\n",
        "\n",
        "if os.path.exists(\"./models_exp1/training_info.json\"):\n",
        "    with open(\"./models_exp1/training_info.json\", \"r\") as f:\n",
        "        info = json.load(f)\n",
        "    \n",
        "    print(\"üìä Tr√§ningsresultat (Experiment 1):\")\n",
        "    print(f\"Final accuracy: {info.get('final_accuracy', 'N/A'):.3f}\")\n",
        "    print(f\"Final loss: {info.get('final_loss', 'N/A'):.3f}\")\n",
        "    print(f\"Epochs: {info.get('epochs', 'N/A')}\")\n",
        "    print(f\"Batch size: {info.get('batch_size', 'N/A')}\")\n",
        "else:\n",
        "    print(\"‚ùå Tr√§ningsinfo saknas\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§î Reflektionsfr√•gor\n",
        "\n",
        "<details>\n",
        "<summary>üí≠ Vad h√§nder med √∂verfitting n√§r du h√∂jer epochs?</summary>\n",
        "\n",
        "**Svar**: Med fler epochs kan modellen l√§ra sig tr√§ningsdata f√∂r bra och d√•ligt generalisera till nya data. Detta kallas √∂verfitting.\n",
        "\n",
        "**Experiment**: K√∂r samma tr√§ning men med `--epochs 5` och j√§mf√∂r accuracy p√• tr√§nings- vs valideringsdata.\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>üí≠ Varf√∂r exporterar vi till ONNX (f√∂r Pi/edge)?</summary>\n",
        "\n",
        "**Svar**: ONNX √§r ett standardformat som fungerar p√• m√•nga plattformar (CPU, GPU, mobil, edge). Det g√∂r modellen portabel och optimerad f√∂r inference.\n",
        "\n",
        "**F√∂rdelar**:\n",
        "- Snabbare inference √§n PyTorch\n",
        "- Mindre minnesanv√§ndning\n",
        "- Fungerar p√• Raspberry Pi\n",
        "- St√∂d f√∂r kvantisering (INT8)\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Ditt eget experiment\n",
        "\n",
        "**Uppgift**: Tr√§na en modell med andra inst√§llningar och j√§mf√∂r resultaten.\n",
        "\n",
        "**F√∂rslag**:\n",
        "- √ñka epochs till 3-5\n",
        "- √Ñndra batch_size till 64 eller 256\n",
        "- Testa med och utan `--no-pretrained`\n",
        "\n",
        "**Kod att modifiera**:\n",
        "```python\n",
        "# √Ñndra dessa v√§rden:\n",
        "EPOCHS = 3\n",
        "BATCH_SIZE = 64\n",
        "USE_PRETRAINED = False  # True f√∂r f√∂rtr√§nade vikter\n",
        "\n",
        "!python -m piedge_edukit.train --fakedata --epochs {EPOCHS} --batch-size {BATCH_SIZE} --output-dir ./models_myexp\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Implementera ditt experiment h√§r\n",
        "# √Ñndra v√§rdena nedan och k√∂r tr√§ningen\n",
        "\n",
        "EPOCHS = 3\n",
        "BATCH_SIZE = 64\n",
        "USE_PRETRAINED = False\n",
        "\n",
        "print(f\"üß™ Mitt experiment: epochs={EPOCHS}, batch_size={BATCH_SIZE}, pretrained={USE_PRETRAINED}\")\n",
        "\n",
        "# TODO: K√∂r tr√§ningen med dina inst√§llningar\n",
        "# !python -m piedge_edukit.train --fakedata --epochs {EPOCHS} --batch-size {BATCH_SIZE} --output-dir ./models_myexp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ Sammanfattning\n",
        "\n",
        "Du har nu l√§rt dig:\n",
        "- Vad FakeData √§r och varf√∂r vi anv√§nder det\n",
        "- Hur tr√§ning fungerar med olika hyperparametrar\n",
        "- Varf√∂r ONNX-export √§r viktigt f√∂r edge deployment\n",
        "\n",
        "**N√§sta steg**: G√• till `02_latency_benchmark.ipynb` f√∂r att f√∂rst√• hur vi m√§ter modellens prestanda.\n",
        "\n",
        "**Viktiga begrepp**:\n",
        "- **Epochs**: Antal genomg√•ngar av datasetet\n",
        "- **Batch size**: Antal bilder per tr√§ningssteg\n",
        "- **Pretrained weights**: F√∂rtr√§nade vikter fr√•n ImageNet\n",
        "- **ONNX**: Standardformat f√∂r edge deployment\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
