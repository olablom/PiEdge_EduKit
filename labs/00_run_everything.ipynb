{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ PiEdge EduKit - Quick Run & Sanity Check\n",
    "\n",
    "## What you'll learn today\n",
    "\n",
    "* Train a tiny image classifier in PyTorch\n",
    "* Export the model to **ONNX** (a portable format for deployment)\n",
    "* Measure inference latency and interpret P50/P95\n",
    "* (Try to) quantize to INT8 and understand why it may fail\n",
    "* Evaluate the model and record a reproducible \"receipt\"\n",
    "\n",
    "## Why this matters\n",
    "\n",
    "Most real projects train in Python but deploy elsewhere (C++, mobile, web, embedded). ONNX lets us move models **out of Python** without rewriting the model by hand.\n",
    "\n",
    "## How to use this notebook\n",
    "\n",
    "This is a **smoke test**: it runs the whole pipeline end-to-end so your environment is correct. For learning and coding tasks, continue with **`01_training_and_export.ipynb`** ‚Üí **`04_evaluate_and_verify.ipynb`**.\n",
    "\n",
    "---\n",
    "\n",
    "## ONNX 101\n",
    "\n",
    "**What is ONNX?**\n",
    "ONNX (Open Neural Network Exchange) is an **open standard** for representing ML models as a graph of operators (Conv, Relu, MatMul‚Ä¶). Many frameworks can **export** to ONNX (PyTorch, TensorFlow) and many runtimes can **execute** ONNX (ONNX Runtime, TensorRT, CoreML Tools).\n",
    "\n",
    "**Why ONNX?**\n",
    "\n",
    "* **Portability**: train in Python, deploy in C++/C#/Java/JS, mobile or edge.\n",
    "* **Performance**: runtimes fuse ops and call optimized backends (MKL, cuDNN).\n",
    "* **Interoperability**: one model file can run across platforms with different \"Execution Providers\" (CPU, CUDA, DirectML, NNAPI‚Ä¶).\n",
    "\n",
    "**Key terms**\n",
    "\n",
    "* **Opset**: version of the operator set supported by runtimes. We export with a specific opset (e.g., 17).\n",
    "* **Static vs dynamic shapes**: fixed sizes are simpler/faster; dynamic adds flexibility.\n",
    "* **Execution Provider (EP)**: the backend used by ONNX Runtime (e.g., `CPUExecutionProvider`).\n",
    "* **Pre/Post-processing**: steps around the model (resize, normalize, label mapping). These **aren't** part of the ONNX graph; the app must do the same steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup & Verifiering\n",
    "\n",
    "F√∂rst kontrollerar vi att milj√∂n √§r korrekt:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiet noisy ORT quantizer log line (appears even with correct preprocessing)\n",
    "import logging\n",
    "for name in (\"\", \"onnxruntime\", \"onnxruntime.quantization\"):\n",
    "    logging.getLogger(name).setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Changed working dir to repo root: C:\\Users\\olabl\\Documents\\GitHub\\piedge_edukit\n"
     ]
    }
   ],
   "source": [
    "# Make notebook run from repo root (not labs/) + quiet mode\n",
    "import os, sys, warnings, pathlib\n",
    "\n",
    "# If opened from labs/, change working directory to repo root\n",
    "nb_dir = pathlib.Path.cwd()\n",
    "if nb_dir.name == \"labs\":\n",
    "    os.chdir(nb_dir.parent)\n",
    "    print(\"-> Changed working dir to repo root:\", os.getcwd())\n",
    "\n",
    "# Ensure repo root is importable\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.insert(0, os.getcwd())\n",
    "\n",
    "# Quiet progress bars and some noisy warnings\n",
    "os.environ.setdefault(\"TQDM_DISABLE\", \"1\")  # hide tqdm progress bars\n",
    "os.environ.setdefault(\"PYTHONWARNINGS\", \"ignore\")\n",
    "os.environ.setdefault(\"ORT_LOG_SEVERITY_LEVEL\", \"3\")  # ORT info/warn -> quiet\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"onnxruntime\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa: E401\n",
    "# Cross-platform runner + live clock (no shell redirection needed)\n",
    "import sys\n",
    "import subprocess\n",
    "import time\n",
    "import threading\n",
    "import shutil\n",
    "from contextlib import contextmanager\n",
    "from IPython.display import display\n",
    "\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    _HAVE_WIDGETS = True\n",
    "except Exception:\n",
    "    _HAVE_WIDGETS = False\n",
    "\n",
    "@contextmanager\n",
    "def running_timer(label=\"Running‚Ä¶\"):\n",
    "    start = time.time()\n",
    "    symbols = [\"üïê\",\"üïë\",\"üïí\",\"üïì\",\"üïî\",\"üïï\",\"üïñ\",\"üïó\",\"üïò\",\"üïô\",\"üïö\",\"üïõ\"]\n",
    "    stop = False\n",
    "\n",
    "    if _HAVE_WIDGETS:\n",
    "        w = widgets.HTML()\n",
    "        display(w)\n",
    "        def _tick():\n",
    "            k = 0\n",
    "            while not stop:\n",
    "                w.value = f\"<b>{symbols[k%12]}</b> {label} &nbsp; <code>{time.time()-start:.1f}s</code>\"\n",
    "                time.sleep(0.5); k += 1\n",
    "        t = threading.Thread(target=_tick, daemon=True); t.start()\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            stop = True; t.join(timeout=0.2)\n",
    "            w.value = f\"‚úÖ Done ‚Äî <code>{time.time()-start:.1f}s</code>\"\n",
    "    else:\n",
    "        width = shutil.get_terminal_size((80, 20)).columns\n",
    "        def _tick():\n",
    "            k = 0\n",
    "            while not stop:\n",
    "                msg = f\"{symbols[k%12]} {label}  {time.time()-start:.1f}s\"\n",
    "                print(\"\\r\" + msg[:width].ljust(width), end=\"\")\n",
    "                time.sleep(0.5); k += 1\n",
    "            print()\n",
    "        t = threading.Thread(target=_tick, daemon=True); t.start()\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            stop = True; t.join(timeout=0.2)\n",
    "            print(f\"‚úÖ Done ‚Äî {time.time()-start:.1f}s\")\n",
    "\n",
    "def run_module(label, module, *args):\n",
    "    \"\"\"Run `python -m <module> <args>` cross-platform, capture output, raise on error.\"\"\"\n",
    "    with running_timer(label):\n",
    "        cmd = [sys.executable, \"-W\", \"ignore\", \"-m\", module, *map(str, args)]\n",
    "        proc = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "        print(proc.stdout)\n",
    "        if proc.returncode != 0:\n",
    "            raise RuntimeError(f\"{module} exited with code {proc.returncode}\")\n",
    "\n",
    "def run_script(label, path, *args):\n",
    "    \"\"\"Run `python <path> <args>` cross-platform, capture output, raise on error.\"\"\"\n",
    "    with running_timer(label):\n",
    "        cmd = [sys.executable, \"-W\", \"ignore\", path, *map(str, args)]\n",
    "        proc = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "        print(proc.stdout)\n",
    "        if proc.returncode != 0:\n",
    "            raise RuntimeError(f\"{path} exited with code {proc.returncode}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.10 (tags/v3.12.10:0cc8128, Apr  8 2025, 12:21:36) [MSC v.1943 64 bit (AMD64)]\n",
      "‚úÖ PiEdge EduKit package OK\n"
     ]
    }
   ],
   "source": [
    "# Milj√∂koll + sj√§lvl√§kning (Python 3.12 + editable install)\n",
    "import sys, os, importlib, subprocess\n",
    "print(f\"Python version: {sys.version}\")\n",
    "assert sys.version_info[:2] == (3, 12), f\"Python 3.12 kr√§vs, du har {sys.version_info[:2]}\"\n",
    "\n",
    "try:\n",
    "    import piedge_edukit  # noqa: F401\n",
    "    print(\"‚úÖ PiEdge EduKit package OK\")\n",
    "except ModuleNotFoundError:\n",
    "    # Hitta repo-roten: om vi st√•r i labs/, g√• ett steg upp\n",
    "    repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\")) if os.path.basename(os.getcwd()) == \"labs\" else os.getcwd()\n",
    "    print(\"‚ö† Package saknas ‚Äì installerar editable fr√•n:\", repo_root)\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", repo_root])\n",
    "    importlib.invalidate_caches()\n",
    "    import piedge_edukit  # noqa: F401\n",
    "    print(\"‚úÖ Package installerat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Paketet importeras ‚Äì k√∂r vidare!\n"
     ]
    }
   ],
   "source": [
    "# Paketet ska redan vara installerat av cellen ovan. Enkel sanity:\n",
    "import piedge_edukit\n",
    "print(\"‚úÖ Paketet importeras ‚Äì k√∂r vidare!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Tr√§ning & ONNX Export\n",
    "\n",
    "Tr√§nar en liten modell med FakeData och exporterar till ONNX:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36dffbb1954b44a0a74e45aa71d07d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "[INFO] Using FakeData for training (no real images)\n",
      "Preparing data...\n",
      "Set 2 classes: ['class0', 'class1']\n",
      "Training model with 2 classes...\n",
      "Classes: ['class0', 'class1']\n",
      "\n",
      "Epoch 1/1\n",
      "Train Loss: 0.7062, Train Acc: 51.00%\n",
      "Val Loss: 0.6809, Val Acc: 65.00%\n",
      "\n",
      "Training completed! Best validation accuracy: 65.00%\n",
      "Exporting model to ONNX...\n",
      "[OK] Model exported to models\\model.onnx (opset 17)\n",
      "[OK] ONNX model verified successfully\n",
      "  Input shape: (1, 3, 64, 64)\n",
      "  Output shape: (1, 2)\n",
      "  Output dtype: float32\n",
      "[OK] Preprocessing configuration valid (hash: 9f9a96cb4a32eea9)\n",
      "[OK] Labels valid: 2 classes\n",
      "[OK] Model exported successfully to models\\model.onnx\n",
      "[OK] Training and export completed successfully!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tr√§na modell (snabb k√∂rning f√∂r demo)\n",
    "run_module(\"Training (FakeData)\",\n",
    "           \"piedge_edukit.train\",\n",
    "           \"--fakedata\", \"--no-pretrained\",\n",
    "           \"--epochs\", 1, \"--batch-size\", 256,\n",
    "           \"--output-dir\", \"./models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ONNX-modell skapad: 8.5 MB\n"
     ]
    }
   ],
   "source": [
    "# Kontrollera att modellen skapades\n",
    "import os\n",
    "if os.path.exists(\"./models/model.onnx\"):\n",
    "    size_mb = os.path.getsize(\"./models/model.onnx\") / (1024*1024)\n",
    "    print(f\"‚úÖ ONNX-modell skapad: {size_mb:.1f} MB\")\n",
    "else:\n",
    "    print(\"‚ùå ONNX-modell saknas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Latensbenchmark\n",
    "\n",
    "M√§ter hur snabb modellen √§r p√• CPU:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "890fd8b56cc44b37866cfda7f7096544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting latency benchmark...\n",
      "Model: models\\model.onnx\n",
      "Data: None\n",
      "Output: reports\n",
      "[OK] Model loaded successfully\n",
      "  Providers: ['CPUExecutionProvider']\n",
      "  Input shape: ['batch_size', 3, 64, 64]\n",
      "  Output shape: ['batch_size', 2]\n",
      "[INFO] Generating fake test data for benchmarking\n",
      "[OK] Generated 50 fake test images\n",
      "Running 1 warmup iterations...\n",
      "[OK] Warmup completed\n",
      "Running 3 benchmark iterations...\n",
      "[OK] Results saved to reports\n",
      "[OK] Plot saved to reports\\latency_plot.png\n",
      "\n",
      "==================================================\n",
      "BENCHMARK RESULTS\n",
      "==================================================\n",
      "Mean latency: 0.517 ms\n",
      "P50 latency:  0.509 ms\n",
      "P95 latency:  0.538 ms\n",
      "Std deviation: 0.018 ms\n",
      "==================================================\n",
      "\n",
      "[OK] Benchmark completed successfully!\n",
      "Results saved to: reports\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K√∂r benchmark (snabb k√∂rning)\n",
    "run_module(\"Benchmarking (CPU)\",\n",
    "           \"piedge_edukit.benchmark\",\n",
    "           \"--fakedata\",\n",
    "           \"--model-path\", \"./models/model.onnx\",\n",
    "           \"--warmup\", 1, \"--runs\", 3,\n",
    "           \"--providers\", \"CPUExecutionProvider\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Benchmark-resultat:\n",
      "PiEdge EduKit - Latency Benchmark Results\n",
      "==================================================\n",
      "\n",
      "Version: 0.1.0\n",
      "Generated: 2025-10-01 15:30:50\n",
      "\n",
      "Version Information:\n",
      "  Python: 3.12.10\n",
      "  ONNX Runtime: 1.18.0\n",
      "  Platform: Windows-11-10.0.26100-SP0\n",
      "  Device: PC/Laptop\n",
      "\n",
      "System Information:\n",
      "  cpu_count: 20\n",
      "  memory_gb: 63.39\n",
      "  piedge_edukit_version: 0.1.0\n",
      "  cpu_governor: N/A\n",
      "\n",
      "Benchmark Configuration:\n",
      "  Model: model.onnx\n",
      "  Warmup runs: 1\n",
      "  Benchmark runs: 3\n",
      "  Batch size: 1\n",
      "\n",
      "Latency Statistics (ms):\n",
      "  Mean: 0.517\n",
      "  Std:  0.018\n",
      "  Min:  0.499\n",
      "  Max:  0.541\n",
      "  P50:  0.509\n",
      "  P95:  0.538\n",
      "  P99:  0.541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visa benchmark-resultat\n",
    "if os.path.exists(\"./reports/latency_summary.txt\"):\n",
    "    with open(\"./reports/latency_summary.txt\", \"r\") as f:\n",
    "        print(\"üìä Benchmark-resultat:\")\n",
    "        print(f.read())\n",
    "else:\n",
    "    print(\"‚ùå Benchmark-rapport saknas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Kvantisering (INT8)\n",
    "\n",
    "Komprimerar modellen f√∂r snabbare inference:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Setting up calibration data (best practice: reuse real training images)\n",
      "   Creating fallback calibration dataset...\n",
      "‚úÖ Created 32 fallback calibration images in data\\train\n",
      "   Source: Synthetic PNG files (organized like real training data)\n",
      "   ‚Üí Using --data-path ensures correct preprocessing (no ORT warning!)\n"
     ]
    }
   ],
   "source": [
    "# Best Practice: Use real training images for calibration\n",
    "# This ensures correct preprocessing and avoids ORT warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "print(\"üìä Setting up calibration data (best practice: reuse real training images)\")\n",
    "\n",
    "# Create tiny calibration image set if data/train/ is missing\n",
    "calib_dir = Path(\"data/train\")\n",
    "if not calib_dir.exists() or not any(calib_dir.rglob(\"*.png\")):\n",
    "    print(\"   Creating fallback calibration dataset...\")\n",
    "    for cls in [\"class0\", \"class1\"]:\n",
    "        (calib_dir / cls).mkdir(parents=True, exist_ok=True)\n",
    "        for i in range(16):  # 32 total (16 per class)\n",
    "            # Synthetic but \"real\" PNG files\n",
    "            arr = (np.random.rand(64, 64, 3) * 255).astype(np.uint8)\n",
    "            Image.fromarray(arr).save(calib_dir / cls / f\"sample_{i:02d}.png\")\n",
    "    print(f\"‚úÖ Created 32 fallback calibration images in {calib_dir}\")\n",
    "    print(f\"   Source: Synthetic PNG files (organized like real training data)\")\n",
    "else:\n",
    "    num_samples = sum(1 for p in calib_dir.rglob(\"*.png\"))\n",
    "    print(f\"‚úÖ Found {num_samples} existing images in {calib_dir}\")\n",
    "    print(f\"   Source: Real training data\")\n",
    "\n",
    "print(\"   ‚Üí Using --data-path ensures correct preprocessing (no ORT warning!)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7900da5fc84bab924ea420d522b496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n",
      "Starting quantization benchmark...\n",
      "FP32 Model: models\\model.onnx\n",
      "Data: data\\train\n",
      "Output: reports\n",
      "[OK] Preprocessing configuration valid (hash: 9f9a96cb4a32eea9)\n",
      "[OK] Labels valid: 2 classes\n",
      "Found 32 calibration images\n",
      "Preprocessed 32 calibration images\n",
      "Quantizing model to INT8...\n",
      "[ERROR] Quantization failed: 'list' object has no attribute 'get_next'\n",
      "This may be due to unsupported operations or ONNX Runtime version.\n",
      "Continuing with FP32 model only.\n",
      "\n",
      "Benchmarking FP32 model...\n",
      "Benchmarking FP32 model...\n",
      "Benchmarking FP32 model...\n",
      "\n",
      "Skipping INT8 benchmarking (quantization failed)\n",
      "[OK] Comparison results saved to reports\n",
      "[OK] Comparison plot saved to reports\\quantization_comparison.png\n",
      "\n",
      "============================================================\n",
      "QUANTIZATION BENCHMARK RESULTS\n",
      "============================================================\n",
      "Quantization Status: FAILED\n",
      "Error: INT8 quantization failed - continuing with FP32 only\n",
      "FP32 Latency: 0.590 ms\n",
      "FP32 Size: 8.47 MB\n",
      "============================================================\n",
      "\n",
      "[OK] Quantization benchmark completed successfully!\n",
      "Results saved to: reports\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K√∂r kvantisering med RIKTIGA tr√§ningsbilder (korrekt preprocessing, ingen ORT-varning!)\n",
    "try:\n",
    "    if calib_dir.exists():\n",
    "        # Use real training data - same preprocessing as model was trained with\n",
    "        run_module(\"Quantization (INT8 with real calibration data)\",\n",
    "                   \"piedge_edukit.quantization\",\n",
    "                   \"--data-path\", str(calib_dir),\n",
    "                   \"--model-path\", \"./models/model.onnx\",\n",
    "                   \"--calib-size\", 32)\n",
    "    else:\n",
    "        # Fallback to FakeData (will show ORT warning)\n",
    "        run_module(\"Quantization (INT8 attempt with FakeData)\",\n",
    "                   \"piedge_edukit.quantization\",\n",
    "                   \"--fakedata\",\n",
    "                   \"--model-path\", \"./models/model.onnx\",\n",
    "                   \"--calib-size\", 16)\n",
    "except RuntimeError as e:\n",
    "    print(\"‚ö†Ô∏è Quantization step failed (OK for demo):\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Kvantiseringsresultat:\n",
      "PiEdge EduKit - Quantization Comparison Results\n",
      "============================================================\n",
      "\n",
      "Version: 0.1.0\n",
      "Generated: 2025-10-01 15:31:03\n",
      "\n",
      "Model Comparison:\n",
      "  FP32 Size: 8.47 MB\n",
      "  INT8 Size: N/A (quantization failed)\n",
      "  Size Reduction: N/A (quantization failed)\n",
      "\n",
      "Latency Comparison:\n",
      "  FP32 Mean: 0.590 ms\n",
      "  INT8 Mean: N/A (quantization failed)\n",
      "  Speedup: N/A (quantization failed)\n",
      "\n",
      "Accuracy Comparison: N/A (quantization failed)\n",
      "\n",
      "\n",
      "‚ÑπÔ∏è INT8-kvantisering kan fallera p√• vissa milj√∂er. I denna lektion √§r **FP32** godk√§nt; verify accepterar fallback.\n"
     ]
    }
   ],
   "source": [
    "# Visa kvantiseringsresultat\n",
    "if os.path.exists(\"./reports/quantization_summary.txt\"):\n",
    "    with open(\"./reports/quantization_summary.txt\", \"r\") as f:\n",
    "        print(\"‚ö° Kvantiseringsresultat:\")\n",
    "        print(f.read())\n",
    "else:\n",
    "    print(\"‚ùå Kvantiseringsrapport saknas\")\n",
    "\n",
    "# Tydlig notis om INT8-fail\n",
    "print(\"\\n‚ÑπÔ∏è INT8-kvantisering kan fallera p√• vissa milj√∂er. I denna lektion √§r **FP32** godk√§nt; verify accepterar fallback.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Utv√§rdering & Verifiering\n",
    "\n",
    "Testar modellen och genererar kvitto:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e20e73b71e244aeb6db0c5402f1dfc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote reports/confusion_matrix.png and reports/eval_summary.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K√∂r utv√§rdering\n",
    "run_script(\"Evaluating ONNX\",\n",
    "           \"scripts/evaluate_onnx.py\",\n",
    "           \"--model\", \"./models/model.onnx\",\n",
    "           \"--fakedata\", \"--limit\", 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96809838955441e9a8cc689a17d9d3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K√∂r verifiering och generera kvitto\n",
    "run_script(\"Verifying & generating receipt\", \"verify.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Verifieringskvitto:\n",
      "Status: ‚úÖ PASS\n",
      "Timestamp: 2025-10-01T13:31:11.654172Z\n",
      "\n",
      "Kontroller:\n",
      "  ‚úÖ artifacts_exist: All required artifacts present\n",
      "  ‚úÖ latency_summary_parse: Successfully parsed latency metrics\n",
      "  ‚úÖ quantization_report_exists: Quantization report exists\n",
      "  ‚úÖ quant_speedup_or_fallback: INT8 quantization failed - fallback accepted\n",
      "  ‚úÖ evaluation_reports_exist: Evaluation reports present\n"
     ]
    }
   ],
   "source": [
    "# Visa kvitto\n",
    "import json\n",
    "if os.path.exists(\"./progress/receipt.json\"):\n",
    "    with open(\"./progress/receipt.json\", \"r\") as f:\n",
    "        receipt = json.load(f)\n",
    "    print(\"üìã Verifieringskvitto:\")\n",
    "    print(f\"Status: {'‚úÖ PASS' if receipt['pass'] else '‚ùå FAIL'}\")\n",
    "    print(f\"Timestamp: {receipt['timestamp']}\")\n",
    "    print(\"\\nKontroller:\")\n",
    "    for check in receipt['checks']:\n",
    "        status = \"‚úÖ\" if check['ok'] else \"‚ùå\"\n",
    "        print(f\"  {status} {check['name']}: {check['reason']}\")\n",
    "else:\n",
    "    print(\"‚ùå Kvitto saknas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Klar!\n",
    "\n",
    "Du har nu k√∂rt hela PiEdge EduKit-lektionen! \n",
    "\n",
    "**N√§sta steg**: G√• till `01_training_and_export.ipynb` f√∂r att f√∂rst√• vad som h√§nde under tr√§ningen.\n",
    "\n",
    "**Genererade filer**:\n",
    "- `models/model.onnx` - Tr√§nad modell\n",
    "- `reports/` - Benchmark och kvantiseringsrapporter\n",
    "- `progress/receipt.json` - Verifieringskvitto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-Glossary\n",
    "\n",
    "* **ONNX**: portable model format defined as an operator graph.\n",
    "* **Opset**: versioned set of operators supported by runtimes.\n",
    "* **Execution Provider (EP)**: backend used by ONNX Runtime (CPU, CUDA, DirectML‚Ä¶).\n",
    "* **Latency**: time per request; **Throughput**: requests per second.\n",
    "* **P50/P95/P99**: latency percentiles; tails indicate rare slow requests.\n",
    "* **Quantization (PTQ)**: convert FP32 to INT8 using calibration data.\n",
    "* **Calibration**: running representative samples to estimate activation ranges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (piedge)",
   "language": "python",
   "name": "piedge-edukit-312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
